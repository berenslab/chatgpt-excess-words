{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/']\n"
     ]
    }
   ],
   "source": [
    "# FIX VSCODE PATH PROBLEM -- DELETE AFTER\n",
    "import sys\n",
    "\n",
    "# add path\n",
    "sys.path.append(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/\"\n",
    ")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from process_pubmed_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../figures\")\n",
    "data_path = Path(\"../data\")\n",
    "berenslab_data_path = Path(\"/gpfs01/berens/data/data/pubmed_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/results/variables\n"
     ]
    }
   ],
   "source": [
    "print(variables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "\n",
    "nb_path = Path(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts\"\n",
    ")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract from PubMed's metadata `.xml` files the following:\n",
    "- PubMed ID\n",
    "- title\n",
    "- abstract\n",
    "- language\n",
    "- journal title\n",
    "- ISSN\n",
    "- publication date\n",
    "- (first and last) author first names\n",
    "- (first and last) author Affiliations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2025 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed25n0001.xml\n",
      "pubmed25n0002.xml\n",
      "pubmed25n0003.xml\n",
      "pubmed25n0004.xml\n",
      "pubmed25n0005.xml\n",
      "pubmed25n0006.xml\n",
      "pubmed25n0007.xml\n",
      "pubmed25n0008.xml\n",
      "pubmed25n0009.xml\n",
      "pubmed25n0010.xml\n",
      "pubmed25n0011.xml\n",
      "pubmed25n0012.xml\n",
      "pubmed25n0013.xml\n",
      "pubmed25n0014.xml\n",
      "pubmed25n0015.xml\n",
      "pubmed25n0016.xml\n",
      "pubmed25n0017.xml\n",
      "pubmed25n0018.xml\n",
      "pubmed25n0019.xml\n",
      "pubmed25n0020.xml\n",
      "pubmed25n0021.xml\n",
      "pubmed25n0022.xml\n",
      "pubmed25n0023.xml\n",
      "pubmed25n0024.xml\n",
      "pubmed25n0025.xml\n",
      "pubmed25n0026.xml\n",
      "pubmed25n0027.xml\n",
      "pubmed25n0028.xml\n",
      "pubmed25n0029.xml\n",
      "pubmed25n0030.xml\n",
      "pubmed25n0031.xml\n",
      "pubmed25n0032.xml\n",
      "pubmed25n0033.xml\n",
      "pubmed25n0034.xml\n",
      "pubmed25n0035.xml\n",
      "pubmed25n0036.xml\n",
      "pubmed25n0037.xml\n",
      "pubmed25n0038.xml\n",
      "pubmed25n0039.xml\n",
      "pubmed25n0040.xml\n",
      "pubmed25n0041.xml\n",
      "pubmed25n0042.xml\n",
      "pubmed25n0043.xml\n",
      "pubmed25n0044.xml\n",
      "pubmed25n0045.xml\n",
      "pubmed25n0046.xml\n",
      "pubmed25n0047.xml\n",
      "pubmed25n0048.xml\n",
      "pubmed25n0049.xml\n",
      "pubmed25n0050.xml\n",
      "pubmed25n0051.xml\n",
      "pubmed25n0052.xml\n",
      "pubmed25n0053.xml\n",
      "pubmed25n0054.xml\n",
      "pubmed25n0055.xml\n",
      "pubmed25n0056.xml\n",
      "pubmed25n0057.xml\n",
      "pubmed25n0058.xml\n",
      "pubmed25n0059.xml\n",
      "pubmed25n0060.xml\n",
      "pubmed25n0061.xml\n",
      "pubmed25n0062.xml\n",
      "pubmed25n0063.xml\n",
      "pubmed25n0064.xml\n",
      "pubmed25n0065.xml\n",
      "pubmed25n0066.xml\n",
      "pubmed25n0067.xml\n",
      "pubmed25n0068.xml\n",
      "pubmed25n0069.xml\n",
      "pubmed25n0070.xml\n",
      "pubmed25n0071.xml\n",
      "pubmed25n0072.xml\n",
      "pubmed25n0073.xml\n",
      "pubmed25n0074.xml\n",
      "pubmed25n0075.xml\n",
      "pubmed25n0076.xml\n",
      "pubmed25n0077.xml\n",
      "pubmed25n0078.xml\n",
      "pubmed25n0079.xml\n",
      "pubmed25n0080.xml\n",
      "pubmed25n0081.xml\n",
      "pubmed25n0082.xml\n",
      "pubmed25n0083.xml\n",
      "pubmed25n0084.xml\n",
      "pubmed25n0085.xml\n",
      "pubmed25n0086.xml\n",
      "pubmed25n0087.xml\n",
      "pubmed25n0088.xml\n",
      "pubmed25n0089.xml\n",
      "pubmed25n0090.xml\n",
      "pubmed25n0091.xml\n",
      "pubmed25n0092.xml\n",
      "pubmed25n0093.xml\n",
      "pubmed25n0094.xml\n",
      "pubmed25n0095.xml\n",
      "pubmed25n0096.xml\n",
      "pubmed25n0097.xml\n",
      "pubmed25n0098.xml\n",
      "pubmed25n0099.xml\n",
      "pubmed25n0100.xml\n",
      "pubmed25n0101.xml\n",
      "pubmed25n0102.xml\n",
      "pubmed25n0103.xml\n",
      "pubmed25n0104.xml\n",
      "pubmed25n0105.xml\n",
      "pubmed25n0106.xml\n",
      "pubmed25n0107.xml\n",
      "pubmed25n0108.xml\n",
      "pubmed25n0109.xml\n",
      "pubmed25n0110.xml\n",
      "pubmed25n0111.xml\n",
      "pubmed25n0112.xml\n",
      "pubmed25n0113.xml\n",
      "pubmed25n0114.xml\n",
      "pubmed25n0115.xml\n",
      "pubmed25n0116.xml\n",
      "pubmed25n0117.xml\n",
      "pubmed25n0118.xml\n",
      "pubmed25n0119.xml\n",
      "pubmed25n0120.xml\n",
      "pubmed25n0121.xml\n",
      "pubmed25n0122.xml\n",
      "pubmed25n0123.xml\n",
      "pubmed25n0124.xml\n",
      "pubmed25n0125.xml\n",
      "pubmed25n0126.xml\n",
      "pubmed25n0127.xml\n",
      "pubmed25n0128.xml\n",
      "pubmed25n0129.xml\n",
      "pubmed25n0130.xml\n",
      "pubmed25n0131.xml\n",
      "pubmed25n0132.xml\n",
      "pubmed25n0133.xml\n",
      "pubmed25n0134.xml\n",
      "pubmed25n0135.xml\n",
      "pubmed25n0136.xml\n",
      "pubmed25n0137.xml\n",
      "pubmed25n0138.xml\n",
      "pubmed25n0139.xml\n",
      "pubmed25n0140.xml\n",
      "pubmed25n0141.xml\n",
      "pubmed25n0142.xml\n",
      "pubmed25n0143.xml\n",
      "pubmed25n0144.xml\n",
      "pubmed25n0145.xml\n",
      "pubmed25n0146.xml\n",
      "pubmed25n0147.xml\n",
      "pubmed25n0148.xml\n",
      "pubmed25n0149.xml\n",
      "pubmed25n0150.xml\n",
      "pubmed25n0151.xml\n",
      "pubmed25n0152.xml\n",
      "pubmed25n0153.xml\n",
      "pubmed25n0154.xml\n",
      "pubmed25n0155.xml\n",
      "pubmed25n0156.xml\n",
      "pubmed25n0157.xml\n",
      "pubmed25n0158.xml\n",
      "pubmed25n0159.xml\n",
      "pubmed25n0160.xml\n",
      "pubmed25n0161.xml\n",
      "pubmed25n0162.xml\n",
      "pubmed25n0163.xml\n",
      "pubmed25n0164.xml\n",
      "pubmed25n0165.xml\n",
      "pubmed25n0166.xml\n",
      "pubmed25n0167.xml\n",
      "pubmed25n0168.xml\n",
      "pubmed25n0169.xml\n",
      "pubmed25n0170.xml\n",
      "pubmed25n0171.xml\n",
      "pubmed25n0172.xml\n",
      "pubmed25n0173.xml\n",
      "pubmed25n0174.xml\n",
      "pubmed25n0175.xml\n",
      "pubmed25n0176.xml\n",
      "pubmed25n0177.xml\n",
      "pubmed25n0178.xml\n",
      "pubmed25n0179.xml\n",
      "pubmed25n0180.xml\n",
      "pubmed25n0181.xml\n",
      "pubmed25n0182.xml\n",
      "pubmed25n0183.xml\n",
      "pubmed25n0184.xml\n",
      "pubmed25n0185.xml\n",
      "pubmed25n0186.xml\n",
      "pubmed25n0187.xml\n",
      "pubmed25n0188.xml\n",
      "pubmed25n0189.xml\n",
      "pubmed25n0190.xml\n",
      "pubmed25n0191.xml\n",
      "pubmed25n0192.xml\n",
      "pubmed25n0193.xml\n",
      "pubmed25n0194.xml\n",
      "pubmed25n0195.xml\n",
      "pubmed25n0196.xml\n",
      "pubmed25n0197.xml\n",
      "pubmed25n0198.xml\n",
      "pubmed25n0199.xml\n",
      "pubmed25n0200.xml\n",
      "pubmed25n0201.xml\n",
      "pubmed25n0202.xml\n",
      "pubmed25n0203.xml\n",
      "pubmed25n0204.xml\n",
      "pubmed25n0205.xml\n",
      "pubmed25n0206.xml\n",
      "pubmed25n0207.xml\n",
      "pubmed25n0208.xml\n",
      "pubmed25n0209.xml\n",
      "pubmed25n0210.xml\n",
      "pubmed25n0211.xml\n",
      "pubmed25n0212.xml\n",
      "pubmed25n0213.xml\n",
      "pubmed25n0214.xml\n",
      "pubmed25n0215.xml\n",
      "pubmed25n0216.xml\n",
      "pubmed25n0217.xml\n",
      "pubmed25n0218.xml\n",
      "pubmed25n0219.xml\n",
      "pubmed25n0220.xml\n",
      "pubmed25n0221.xml\n",
      "pubmed25n0222.xml\n",
      "pubmed25n0223.xml\n",
      "pubmed25n0224.xml\n",
      "pubmed25n0225.xml\n",
      "pubmed25n0226.xml\n",
      "pubmed25n0227.xml\n",
      "pubmed25n0228.xml\n",
      "pubmed25n0229.xml\n",
      "pubmed25n0230.xml\n",
      "pubmed25n0231.xml\n",
      "pubmed25n0232.xml\n",
      "pubmed25n0233.xml\n",
      "pubmed25n0234.xml\n",
      "pubmed25n0235.xml\n",
      "pubmed25n0236.xml\n",
      "pubmed25n0237.xml\n",
      "pubmed25n0238.xml\n",
      "pubmed25n0239.xml\n",
      "pubmed25n0240.xml\n",
      "pubmed25n0241.xml\n",
      "pubmed25n0242.xml\n",
      "pubmed25n0243.xml\n",
      "pubmed25n0244.xml\n",
      "pubmed25n0245.xml\n",
      "pubmed25n0246.xml\n",
      "pubmed25n0247.xml\n",
      "pubmed25n0248.xml\n",
      "pubmed25n0249.xml\n",
      "pubmed25n0250.xml\n",
      "pubmed25n0251.xml\n",
      "pubmed25n0252.xml\n",
      "pubmed25n0253.xml\n",
      "pubmed25n0254.xml\n",
      "pubmed25n0255.xml\n",
      "pubmed25n0256.xml\n",
      "pubmed25n0257.xml\n",
      "pubmed25n0258.xml\n",
      "pubmed25n0259.xml\n",
      "pubmed25n0260.xml\n",
      "pubmed25n0261.xml\n",
      "pubmed25n0262.xml\n",
      "pubmed25n0263.xml\n",
      "pubmed25n0264.xml\n",
      "pubmed25n0265.xml\n",
      "pubmed25n0266.xml\n",
      "pubmed25n0267.xml\n",
      "pubmed25n0268.xml\n",
      "pubmed25n0269.xml\n",
      "pubmed25n0270.xml\n",
      "pubmed25n0271.xml\n",
      "pubmed25n0272.xml\n",
      "pubmed25n0273.xml\n",
      "pubmed25n0274.xml\n",
      "pubmed25n0275.xml\n",
      "pubmed25n0276.xml\n",
      "pubmed25n0277.xml\n",
      "pubmed25n0278.xml\n",
      "pubmed25n0279.xml\n",
      "pubmed25n0280.xml\n",
      "pubmed25n0281.xml\n",
      "pubmed25n0282.xml\n",
      "pubmed25n0283.xml\n",
      "pubmed25n0284.xml\n",
      "pubmed25n0285.xml\n",
      "pubmed25n0286.xml\n",
      "pubmed25n0287.xml\n",
      "pubmed25n0288.xml\n",
      "pubmed25n0289.xml\n",
      "pubmed25n0290.xml\n",
      "pubmed25n0291.xml\n",
      "pubmed25n0292.xml\n",
      "pubmed25n0293.xml\n",
      "pubmed25n0294.xml\n",
      "pubmed25n0295.xml\n",
      "pubmed25n0296.xml\n",
      "pubmed25n0297.xml\n",
      "pubmed25n0298.xml\n",
      "pubmed25n0299.xml\n",
      "pubmed25n0300.xml\n",
      "pubmed25n0301.xml\n",
      "pubmed25n0302.xml\n",
      "pubmed25n0303.xml\n",
      "pubmed25n0304.xml\n",
      "pubmed25n0305.xml\n",
      "pubmed25n0306.xml\n",
      "pubmed25n0307.xml\n",
      "pubmed25n0308.xml\n",
      "pubmed25n0309.xml\n",
      "pubmed25n0310.xml\n",
      "pubmed25n0311.xml\n",
      "pubmed25n0312.xml\n",
      "pubmed25n0313.xml\n",
      "pubmed25n0314.xml\n",
      "pubmed25n0315.xml\n",
      "pubmed25n0316.xml\n",
      "pubmed25n0317.xml\n",
      "pubmed25n0318.xml\n",
      "pubmed25n0319.xml\n",
      "pubmed25n0320.xml\n",
      "pubmed25n0321.xml\n",
      "pubmed25n0322.xml\n",
      "pubmed25n0323.xml\n",
      "pubmed25n0324.xml\n",
      "pubmed25n0325.xml\n",
      "pubmed25n0326.xml\n",
      "pubmed25n0327.xml\n",
      "pubmed25n0328.xml\n",
      "pubmed25n0329.xml\n",
      "pubmed25n0330.xml\n",
      "pubmed25n0331.xml\n",
      "pubmed25n0332.xml\n",
      "pubmed25n0333.xml\n",
      "pubmed25n0334.xml\n",
      "pubmed25n0335.xml\n",
      "pubmed25n0336.xml\n",
      "pubmed25n0337.xml\n",
      "pubmed25n0338.xml\n",
      "pubmed25n0339.xml\n",
      "pubmed25n0340.xml\n",
      "pubmed25n0341.xml\n",
      "pubmed25n0342.xml\n",
      "pubmed25n0343.xml\n",
      "pubmed25n0344.xml\n",
      "pubmed25n0345.xml\n",
      "pubmed25n0346.xml\n",
      "pubmed25n0347.xml\n",
      "pubmed25n0348.xml\n",
      "pubmed25n0349.xml\n",
      "pubmed25n0350.xml\n",
      "pubmed25n0351.xml\n",
      "pubmed25n0352.xml\n",
      "pubmed25n0353.xml\n",
      "pubmed25n0354.xml\n",
      "pubmed25n0355.xml\n",
      "pubmed25n0356.xml\n",
      "pubmed25n0357.xml\n",
      "pubmed25n0358.xml\n",
      "pubmed25n0359.xml\n",
      "pubmed25n0360.xml\n",
      "pubmed25n0361.xml\n",
      "pubmed25n0362.xml\n",
      "pubmed25n0363.xml\n",
      "pubmed25n0364.xml\n",
      "pubmed25n0365.xml\n",
      "pubmed25n0366.xml\n",
      "pubmed25n0367.xml\n",
      "pubmed25n0368.xml\n",
      "pubmed25n0369.xml\n",
      "pubmed25n0370.xml\n",
      "pubmed25n0371.xml\n",
      "pubmed25n0372.xml\n",
      "pubmed25n0373.xml\n",
      "pubmed25n0374.xml\n",
      "pubmed25n0375.xml\n",
      "pubmed25n0376.xml\n",
      "pubmed25n0377.xml\n",
      "pubmed25n0378.xml\n",
      "pubmed25n0379.xml\n",
      "pubmed25n0380.xml\n",
      "pubmed25n0381.xml\n",
      "pubmed25n0382.xml\n",
      "pubmed25n0383.xml\n",
      "pubmed25n0384.xml\n",
      "pubmed25n0385.xml\n",
      "pubmed25n0386.xml\n",
      "pubmed25n0387.xml\n",
      "pubmed25n0388.xml\n",
      "pubmed25n0389.xml\n",
      "pubmed25n0390.xml\n",
      "pubmed25n0391.xml\n",
      "pubmed25n0392.xml\n",
      "pubmed25n0393.xml\n",
      "pubmed25n0394.xml\n",
      "pubmed25n0395.xml\n",
      "pubmed25n0396.xml\n",
      "pubmed25n0397.xml\n",
      "pubmed25n0398.xml\n",
      "pubmed25n0399.xml\n",
      "pubmed25n0400.xml\n",
      "pubmed25n0401.xml\n",
      "pubmed25n0402.xml\n",
      "pubmed25n0403.xml\n",
      "pubmed25n0404.xml\n",
      "pubmed25n0405.xml\n",
      "pubmed25n0406.xml\n",
      "pubmed25n0407.xml\n",
      "pubmed25n0408.xml\n",
      "pubmed25n0409.xml\n",
      "pubmed25n0410.xml\n",
      "pubmed25n0411.xml\n",
      "pubmed25n0412.xml\n",
      "pubmed25n0413.xml\n",
      "pubmed25n0414.xml\n",
      "pubmed25n0415.xml\n",
      "pubmed25n0416.xml\n",
      "pubmed25n0417.xml\n",
      "pubmed25n0418.xml\n",
      "pubmed25n0419.xml\n",
      "pubmed25n0420.xml\n",
      "pubmed25n0421.xml\n",
      "pubmed25n0422.xml\n",
      "pubmed25n0423.xml\n",
      "pubmed25n0424.xml\n",
      "pubmed25n0425.xml\n",
      "pubmed25n0426.xml\n",
      "pubmed25n0427.xml\n",
      "pubmed25n0428.xml\n",
      "pubmed25n0429.xml\n",
      "pubmed25n0430.xml\n",
      "pubmed25n0431.xml\n",
      "pubmed25n0432.xml\n",
      "pubmed25n0433.xml\n",
      "pubmed25n0434.xml\n",
      "pubmed25n0435.xml\n",
      "pubmed25n0436.xml\n",
      "pubmed25n0437.xml\n",
      "pubmed25n0438.xml\n",
      "pubmed25n0439.xml\n",
      "pubmed25n0440.xml\n",
      "pubmed25n0441.xml\n",
      "pubmed25n0442.xml\n",
      "pubmed25n0443.xml\n",
      "pubmed25n0444.xml\n",
      "pubmed25n0445.xml\n",
      "pubmed25n0446.xml\n",
      "pubmed25n0447.xml\n",
      "pubmed25n0448.xml\n",
      "pubmed25n0449.xml\n",
      "pubmed25n0450.xml\n",
      "pubmed25n0451.xml\n",
      "pubmed25n0452.xml\n",
      "pubmed25n0453.xml\n",
      "pubmed25n0454.xml\n",
      "pubmed25n0455.xml\n",
      "pubmed25n0456.xml\n",
      "pubmed25n0457.xml\n",
      "pubmed25n0458.xml\n",
      "pubmed25n0459.xml\n",
      "pubmed25n0460.xml\n",
      "pubmed25n0461.xml\n",
      "pubmed25n0462.xml\n",
      "pubmed25n0463.xml\n",
      "pubmed25n0464.xml\n",
      "pubmed25n0465.xml\n",
      "pubmed25n0466.xml\n",
      "pubmed25n0467.xml\n",
      "pubmed25n0468.xml\n",
      "pubmed25n0469.xml\n",
      "pubmed25n0470.xml\n",
      "pubmed25n0471.xml\n",
      "pubmed25n0472.xml\n",
      "pubmed25n0473.xml\n",
      "pubmed25n0474.xml\n",
      "pubmed25n0475.xml\n",
      "pubmed25n0476.xml\n",
      "pubmed25n0477.xml\n",
      "pubmed25n0478.xml\n",
      "pubmed25n0479.xml\n",
      "pubmed25n0480.xml\n",
      "pubmed25n0481.xml\n",
      "pubmed25n0482.xml\n",
      "pubmed25n0483.xml\n",
      "pubmed25n0484.xml\n",
      "pubmed25n0485.xml\n",
      "pubmed25n0486.xml\n",
      "pubmed25n0487.xml\n",
      "pubmed25n0488.xml\n",
      "pubmed25n0489.xml\n",
      "pubmed25n0490.xml\n",
      "pubmed25n0491.xml\n",
      "pubmed25n0492.xml\n",
      "pubmed25n0493.xml\n",
      "pubmed25n0494.xml\n",
      "pubmed25n0495.xml\n",
      "pubmed25n0496.xml\n",
      "pubmed25n0497.xml\n",
      "pubmed25n0498.xml\n",
      "pubmed25n0499.xml\n",
      "pubmed25n0500.xml\n",
      "pubmed25n0501.xml\n",
      "pubmed25n0502.xml\n",
      "pubmed25n0503.xml\n",
      "pubmed25n0504.xml\n",
      "pubmed25n0505.xml\n",
      "pubmed25n0506.xml\n",
      "pubmed25n0507.xml\n",
      "pubmed25n0508.xml\n",
      "pubmed25n0509.xml\n",
      "pubmed25n0510.xml\n",
      "pubmed25n0511.xml\n",
      "pubmed25n0512.xml\n",
      "pubmed25n0513.xml\n",
      "pubmed25n0514.xml\n",
      "pubmed25n0515.xml\n",
      "pubmed25n0516.xml\n",
      "pubmed25n0517.xml\n",
      "pubmed25n0518.xml\n",
      "pubmed25n0519.xml\n",
      "pubmed25n0520.xml\n",
      "pubmed25n0521.xml\n",
      "pubmed25n0522.xml\n",
      "pubmed25n0523.xml\n",
      "pubmed25n0524.xml\n",
      "pubmed25n0525.xml\n",
      "pubmed25n0526.xml\n",
      "pubmed25n0527.xml\n",
      "pubmed25n0528.xml\n",
      "pubmed25n0529.xml\n",
      "pubmed25n0530.xml\n",
      "pubmed25n0531.xml\n",
      "pubmed25n0532.xml\n",
      "pubmed25n0533.xml\n",
      "pubmed25n0534.xml\n",
      "pubmed25n0535.xml\n",
      "pubmed25n0536.xml\n",
      "pubmed25n0537.xml\n",
      "pubmed25n0538.xml\n",
      "pubmed25n0539.xml\n",
      "pubmed25n0540.xml\n",
      "pubmed25n0541.xml\n",
      "pubmed25n0542.xml\n",
      "pubmed25n0543.xml\n",
      "pubmed25n0544.xml\n",
      "pubmed25n0545.xml\n",
      "pubmed25n0546.xml\n",
      "pubmed25n0547.xml\n",
      "pubmed25n0548.xml\n",
      "pubmed25n0549.xml\n",
      "pubmed25n0550.xml\n",
      "pubmed25n0551.xml\n",
      "pubmed25n0552.xml\n",
      "pubmed25n0553.xml\n",
      "pubmed25n0554.xml\n",
      "pubmed25n0555.xml\n",
      "pubmed25n0556.xml\n",
      "pubmed25n0557.xml\n",
      "pubmed25n0558.xml\n",
      "pubmed25n0559.xml\n",
      "pubmed25n0560.xml\n",
      "pubmed25n0561.xml\n",
      "pubmed25n0562.xml\n",
      "pubmed25n0563.xml\n",
      "pubmed25n0564.xml\n",
      "pubmed25n0565.xml\n",
      "pubmed25n0566.xml\n",
      "pubmed25n0567.xml\n",
      "pubmed25n0568.xml\n",
      "pubmed25n0569.xml\n",
      "pubmed25n0570.xml\n",
      "pubmed25n0571.xml\n",
      "pubmed25n0572.xml\n",
      "pubmed25n0573.xml\n",
      "pubmed25n0574.xml\n",
      "pubmed25n0575.xml\n",
      "pubmed25n0576.xml\n",
      "pubmed25n0577.xml\n",
      "pubmed25n0578.xml\n",
      "pubmed25n0579.xml\n",
      "pubmed25n0580.xml\n",
      "pubmed25n0581.xml\n",
      "pubmed25n0582.xml\n",
      "pubmed25n0583.xml\n",
      "pubmed25n0584.xml\n",
      "pubmed25n0585.xml\n",
      "pubmed25n0586.xml\n",
      "pubmed25n0587.xml\n",
      "pubmed25n0588.xml\n",
      "pubmed25n0589.xml\n",
      "pubmed25n0590.xml\n",
      "pubmed25n0591.xml\n",
      "pubmed25n0592.xml\n",
      "pubmed25n0593.xml\n",
      "pubmed25n0594.xml\n",
      "pubmed25n0595.xml\n",
      "pubmed25n0596.xml\n",
      "pubmed25n0597.xml\n",
      "pubmed25n0598.xml\n",
      "pubmed25n0599.xml\n",
      "pubmed25n0600.xml\n",
      "pubmed25n0601.xml\n",
      "pubmed25n0602.xml\n",
      "pubmed25n0603.xml\n",
      "pubmed25n0604.xml\n",
      "pubmed25n0605.xml\n",
      "pubmed25n0606.xml\n",
      "pubmed25n0607.xml\n",
      "pubmed25n0608.xml\n",
      "pubmed25n0609.xml\n",
      "pubmed25n0610.xml\n",
      "pubmed25n0611.xml\n",
      "pubmed25n0612.xml\n",
      "pubmed25n0613.xml\n",
      "pubmed25n0614.xml\n",
      "pubmed25n0615.xml\n",
      "pubmed25n0616.xml\n",
      "pubmed25n0617.xml\n",
      "pubmed25n0618.xml\n",
      "pubmed25n0619.xml\n",
      "pubmed25n0620.xml\n",
      "pubmed25n0621.xml\n",
      "pubmed25n0622.xml\n",
      "pubmed25n0623.xml\n",
      "pubmed25n0624.xml\n",
      "pubmed25n0625.xml\n",
      "pubmed25n0626.xml\n",
      "pubmed25n0627.xml\n",
      "pubmed25n0628.xml\n",
      "pubmed25n0629.xml\n",
      "pubmed25n0630.xml\n",
      "pubmed25n0631.xml\n",
      "pubmed25n0632.xml\n",
      "pubmed25n0633.xml\n",
      "pubmed25n0634.xml\n",
      "pubmed25n0635.xml\n",
      "pubmed25n0636.xml\n",
      "pubmed25n0637.xml\n",
      "pubmed25n0638.xml\n",
      "pubmed25n0639.xml\n",
      "pubmed25n0640.xml\n",
      "pubmed25n0641.xml\n",
      "pubmed25n0642.xml\n",
      "pubmed25n0643.xml\n",
      "pubmed25n0644.xml\n",
      "pubmed25n0645.xml\n",
      "pubmed25n0646.xml\n",
      "pubmed25n0647.xml\n",
      "pubmed25n0648.xml\n",
      "pubmed25n0649.xml\n",
      "pubmed25n0650.xml\n",
      "pubmed25n0651.xml\n",
      "pubmed25n0652.xml\n",
      "pubmed25n0653.xml\n",
      "pubmed25n0654.xml\n",
      "pubmed25n0655.xml\n",
      "pubmed25n0656.xml\n",
      "pubmed25n0657.xml\n",
      "pubmed25n0658.xml\n",
      "pubmed25n0659.xml\n",
      "pubmed25n0660.xml\n",
      "pubmed25n0661.xml\n",
      "pubmed25n0662.xml\n",
      "pubmed25n0663.xml\n",
      "pubmed25n0664.xml\n",
      "pubmed25n0665.xml\n",
      "pubmed25n0666.xml\n",
      "pubmed25n0667.xml\n",
      "pubmed25n0668.xml\n",
      "pubmed25n0669.xml\n",
      "pubmed25n0670.xml\n",
      "pubmed25n0671.xml\n",
      "pubmed25n0672.xml\n",
      "pubmed25n0673.xml\n",
      "pubmed25n0674.xml\n",
      "pubmed25n0675.xml\n",
      "pubmed25n0676.xml\n",
      "pubmed25n0677.xml\n",
      "pubmed25n0678.xml\n",
      "pubmed25n0679.xml\n",
      "pubmed25n0680.xml\n",
      "pubmed25n0681.xml\n",
      "pubmed25n0682.xml\n",
      "pubmed25n0683.xml\n",
      "pubmed25n0684.xml\n",
      "pubmed25n0685.xml\n",
      "pubmed25n0686.xml\n",
      "pubmed25n0687.xml\n",
      "pubmed25n0688.xml\n",
      "pubmed25n0689.xml\n",
      "pubmed25n0690.xml\n",
      "pubmed25n0691.xml\n",
      "pubmed25n0692.xml\n",
      "pubmed25n0693.xml\n",
      "pubmed25n0694.xml\n",
      "pubmed25n0695.xml\n",
      "pubmed25n0696.xml\n",
      "pubmed25n0697.xml\n",
      "pubmed25n0698.xml\n",
      "pubmed25n0699.xml\n",
      "pubmed25n0700.xml\n",
      "pubmed25n0701.xml\n",
      "pubmed25n0702.xml\n",
      "pubmed25n0703.xml\n",
      "pubmed25n0704.xml\n",
      "pubmed25n0705.xml\n",
      "pubmed25n0706.xml\n",
      "pubmed25n0707.xml\n",
      "pubmed25n0708.xml\n",
      "pubmed25n0709.xml\n",
      "pubmed25n0710.xml\n",
      "pubmed25n0711.xml\n",
      "pubmed25n0712.xml\n",
      "pubmed25n0713.xml\n",
      "pubmed25n0714.xml\n",
      "pubmed25n0715.xml\n",
      "pubmed25n0716.xml\n",
      "pubmed25n0717.xml\n",
      "pubmed25n0718.xml\n",
      "pubmed25n0719.xml\n",
      "pubmed25n0720.xml\n",
      "pubmed25n0721.xml\n",
      "pubmed25n0722.xml\n",
      "pubmed25n0723.xml\n",
      "pubmed25n0724.xml\n",
      "pubmed25n0725.xml\n",
      "pubmed25n0726.xml\n",
      "pubmed25n0727.xml\n",
      "pubmed25n0728.xml\n",
      "pubmed25n0729.xml\n",
      "pubmed25n0730.xml\n",
      "pubmed25n0731.xml\n",
      "pubmed25n0732.xml\n",
      "pubmed25n0733.xml\n",
      "pubmed25n0734.xml\n",
      "pubmed25n0735.xml\n",
      "pubmed25n0736.xml\n",
      "pubmed25n0737.xml\n",
      "pubmed25n0738.xml\n",
      "pubmed25n0739.xml\n",
      "pubmed25n0740.xml\n",
      "pubmed25n0741.xml\n",
      "pubmed25n0742.xml\n",
      "pubmed25n0743.xml\n",
      "pubmed25n0744.xml\n",
      "pubmed25n0745.xml\n",
      "pubmed25n0746.xml\n",
      "pubmed25n0747.xml\n",
      "pubmed25n0748.xml\n",
      "pubmed25n0749.xml\n",
      "pubmed25n0750.xml\n",
      "pubmed25n0751.xml\n",
      "pubmed25n0752.xml\n",
      "pubmed25n0753.xml\n",
      "pubmed25n0754.xml\n",
      "pubmed25n0755.xml\n",
      "pubmed25n0756.xml\n",
      "pubmed25n0757.xml\n",
      "pubmed25n0758.xml\n",
      "pubmed25n0759.xml\n",
      "pubmed25n0760.xml\n",
      "pubmed25n0761.xml\n",
      "pubmed25n0762.xml\n",
      "pubmed25n0763.xml\n",
      "pubmed25n0764.xml\n",
      "pubmed25n0765.xml\n",
      "pubmed25n0766.xml\n",
      "pubmed25n0767.xml\n",
      "pubmed25n0768.xml\n",
      "pubmed25n0769.xml\n",
      "pubmed25n0770.xml\n",
      "pubmed25n0771.xml\n",
      "pubmed25n0772.xml\n",
      "pubmed25n0773.xml\n",
      "pubmed25n0774.xml\n",
      "pubmed25n0775.xml\n",
      "pubmed25n0776.xml\n",
      "pubmed25n0777.xml\n",
      "pubmed25n0778.xml\n",
      "pubmed25n0779.xml\n",
      "pubmed25n0780.xml\n",
      "pubmed25n0781.xml\n",
      "pubmed25n0782.xml\n",
      "pubmed25n0783.xml\n",
      "pubmed25n0784.xml\n",
      "pubmed25n0785.xml\n",
      "pubmed25n0786.xml\n",
      "pubmed25n0787.xml\n",
      "pubmed25n0788.xml\n",
      "pubmed25n0789.xml\n",
      "pubmed25n0790.xml\n",
      "pubmed25n0791.xml\n",
      "pubmed25n0792.xml\n",
      "pubmed25n0793.xml\n",
      "pubmed25n0794.xml\n",
      "pubmed25n0795.xml\n",
      "pubmed25n0796.xml\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = \"/gpfs01/berens/data/data/pubmed/2025_baseline/\"\n",
    "\n",
    "files_2025_df = import_all_files(path, order_files=True)\n",
    "\n",
    "# save results\n",
    "files_2025_df.to_pickle(\n",
    "    \"/gpfs01/berens/data/data/pubmed_processed/files_2025_df\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38201553 papers\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} papers\".format(files_2025_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>AbstractText</th>\n",
       "      <th>Language</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Date</th>\n",
       "      <th>NameFirstAuthor</th>\n",
       "      <th>NameLastAuthor</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>AffiliationFirstAuthor</th>\n",
       "      <th>AffiliationLastAuthor</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Formate assay in body fluids: application in m...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical medicine</td>\n",
       "      <td>1975 Jun</td>\n",
       "      <td>A B</td>\n",
       "      <td>T R</td>\n",
       "      <td>0006-2944</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Delineation of the intimate details of the bac...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Oct 27</td>\n",
       "      <td>K S</td>\n",
       "      <td>R H</td>\n",
       "      <td>1090-2104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Metal substitutions incarbonic anhydrase: a ha...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Oct 27</td>\n",
       "      <td>R J</td>\n",
       "      <td>R G</td>\n",
       "      <td>0006-291X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of chloroquine on cultured fibroblasts:...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Oct 27</td>\n",
       "      <td>U N</td>\n",
       "      <td>N N</td>\n",
       "      <td>1090-2104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atomic models for the polypeptide backbones of...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Oct 27</td>\n",
       "      <td>W A</td>\n",
       "      <td>K B</td>\n",
       "      <td>1090-2104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PMID                                              Title AbstractText  \\\n",
       "0    1  Formate assay in body fluids: application in m...                \n",
       "1    2  Delineation of the intimate details of the bac...                \n",
       "2    3  Metal substitutions incarbonic anhydrase: a ha...                \n",
       "3    4  Effect of chloroquine on cultured fibroblasts:...                \n",
       "4    5  Atomic models for the polypeptide backbones of...                \n",
       "\n",
       "  Language                                            Journal         Date  \\\n",
       "0      eng                               Biochemical medicine     1975 Jun   \n",
       "1      eng  Biochemical and biophysical research communica...  1975 Oct 27   \n",
       "2      eng  Biochemical and biophysical research communica...  1975 Oct 27   \n",
       "3      eng  Biochemical and biophysical research communica...  1975 Oct 27   \n",
       "4      eng  Biochemical and biophysical research communica...  1975 Oct 27   \n",
       "\n",
       "  NameFirstAuthor NameLastAuthor       ISSN AffiliationFirstAuthor  \\\n",
       "0             A B            T R  0006-2944                          \n",
       "1             K S            R H  1090-2104                          \n",
       "2             R J            R G  0006-291X                          \n",
       "3             U N            N N  1090-2104                          \n",
       "4             W A            K B  1090-2104                          \n",
       "\n",
       "  AffiliationLastAuthor           filename  \n",
       "0                        pubmed25n0001.xml  \n",
       "1                        pubmed25n0001.xml  \n",
       "2                        pubmed25n0001.xml  \n",
       "3                        pubmed25n0001.xml  \n",
       "4                        pubmed25n0001.xml  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_2025_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 42.4 s, total: 1min 48s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_2025_df = pd.read_pickle(\n",
    "    \"/gpfs01/berens/data/data/pubmed_processed/files_2025_df\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter\n",
    "\n",
    "Filter out:\n",
    "- non-English papers\n",
    "- papers with empty abstracts\n",
    "- papers with abstracts shorter than 250 or longer than 4000 symbols\n",
    "- papers with unfinished abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty abstracts and non-english papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before, there were 38201553 papers\n",
      "After eliminating empty abstracts, there are 26748681 papers\n",
      "After first cleaning, there are 25122472 papers\n",
      "CPU times: user 19.6 s, sys: 3.56 s, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Before, there were {} papers\".format(files_2025_df.shape[0]))\n",
    "\n",
    "# Eliminate empty abstracts\n",
    "clean_2025_df = files_2025_df[files_2025_df.AbstractText != \"\"]\n",
    "\n",
    "print(\n",
    "    \"After eliminating empty abstracts, there are {} papers\".format(\n",
    "        clean_2025_df.shape[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Eliminate non-english papers\n",
    "clean_2025_df = clean_2025_df[clean_2025_df.Language == \"eng\"]\n",
    "\n",
    "# print size\n",
    "print(\n",
    "    \"After first cleaning, there are {} papers\".format(clean_2025_df.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cut off, there are 25122472 papers\n",
      "After cut off, there are 25103731 papers\n"
     ]
    }
   ],
   "source": [
    "print(\"Before cut off, there are {} papers\".format(clean_2025_df.shape[0]))\n",
    "abstracts = clean_2025_df[\"AbstractText\"].tolist()\n",
    "len_strings = map(len, abstracts)\n",
    "len_abstracts = np.fromiter(len_strings, dtype=np.int64, count=len(abstracts))\n",
    "\n",
    "\n",
    "cut_off = 4000\n",
    "clean_2025_df = clean_2025_df[len_abstracts < cut_off]\n",
    "print(\"After cut off, there are {} papers\".format(clean_2025_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After threshold, there are 24845923 papers\n"
     ]
    }
   ],
   "source": [
    "threshold = 250\n",
    "len_short_abstracts = len_abstracts[len_abstracts < cut_off]\n",
    "clean_2025_df = clean_2025_df[len_short_abstracts > threshold]\n",
    "print(\"After threshold, there are {} papers\".format(clean_2025_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove the truncated sentence from abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = clean_2025_df[\"AbstractText\"]\n",
    "abstracts_list = clean_2025_df[\"AbstractText\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 1.69 s, total: 30.9 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clean_2025_df.AbstractText = list(\n",
    "    map(\n",
    "        lambda x, y: x[: y - 1] if y != -1 else x,\n",
    "        clean_2025_df.AbstractText,\n",
    "        clean_2025_df.AbstractText.str.find(\"ABSTRACT TRUNCATED AT\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unfinished abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24845923\n"
     ]
    }
   ],
   "source": [
    "abstracts = clean_2025_df[\"AbstractText\"]\n",
    "abstracts_list = clean_2025_df[\"AbstractText\"].tolist()\n",
    "print(len(abstracts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 s, sys: 1.06 s, total: 5.64 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "end_abstracts = [x[-2:] for x in abstracts_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.18 s, sys: 61 ms, total: 9.24 s\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "point_index = np.array([x.find(\".\") for x in end_abstracts])\n",
    "question_index = np.array([x.find(\"?\") for x in end_abstracts])\n",
    "exclamation_index = np.array([x.find(\"!\") for x in end_abstracts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning, there are 24845923 papers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, there are 24817977 papers\n",
      "CPU times: user 6.79 s, sys: 5.62 s, total: 12.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Before cleaning, there are {} papers\".format(clean_2025_df.shape[0]))\n",
    "\n",
    "# Eliminate unfinished abstracts\n",
    "clean_2025_df = clean_2025_df[\n",
    "    (point_index != -1) | (question_index != -1) | (exclamation_index != -1)\n",
    "]\n",
    "\n",
    "# print size\n",
    "print(\"After cleaning, there are {} papers\".format(clean_2025_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23701/3428046920.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  clean_2025_df.Date.loc[31304337] = \"2020\"\n"
     ]
    }
   ],
   "source": [
    "# Fix the issue of one paper having the wronge date that does not satisfy the pattern \"([12]\\d\\d\\d)\"\n",
    "# Paper with PMID: 32764183, wrong date: \"3276 4183\", right date (according to PubMed): \"2020\"\n",
    "\n",
    "assert clean_2025_df.PMID.loc[31304337] == \"32764183\"\n",
    "assert clean_2025_df.Date.loc[31304337] == \"3276 4183\"\n",
    "clean_2025_df.Date.loc[31304337] = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the issue of one paper having the wronge date that does not satisfy the pattern \"([12]\\d\\d\\d)\"\n",
    "# Paper with PMID: 31151109, wrong date: \"3115 1109\", right date (according to PubMed): \"2019\"\n",
    "\n",
    "assert clean_2025_df.PMID.loc[29734806] == \"31151109\"\n",
    "assert clean_2025_df.Date.loc[29734806] == \"3115 1109\"\n",
    "clean_2025_df.Date.loc[29734806] = \"2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>AbstractText</th>\n",
       "      <th>Language</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Date</th>\n",
       "      <th>NameFirstAuthor</th>\n",
       "      <th>NameLastAuthor</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>AffiliationFirstAuthor</th>\n",
       "      <th>AffiliationLastAuthor</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>Influence of a new virostatic compound on the ...</td>\n",
       "      <td>The virostatic compound N,N-diethyl-4-[2-(2-ox...</td>\n",
       "      <td>eng</td>\n",
       "      <td>Arzneimittel-Forschung</td>\n",
       "      <td>1975 Sep</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>0004-4172</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Effect of etafenone on total and regional myoc...</td>\n",
       "      <td>The distribution of blood flow to the subendoc...</td>\n",
       "      <td>eng</td>\n",
       "      <td>Arzneimittel-Forschung</td>\n",
       "      <td>1975 Sep</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>0004-4172</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Pharmacological properties of new neuroleptic ...</td>\n",
       "      <td>RMI 61 140, RMI 61 144 and RMI 61 280 are newl...</td>\n",
       "      <td>eng</td>\n",
       "      <td>Arzneimittel-Forschung</td>\n",
       "      <td>1975 Sep</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0004-4172</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Lysosomal hydrolases of the epidermis. I. Glyc...</td>\n",
       "      <td>Seven distinct glycosidases (EC 3.2) have been...</td>\n",
       "      <td>eng</td>\n",
       "      <td>The British journal of dermatology</td>\n",
       "      <td>1975 Jul</td>\n",
       "      <td>P D</td>\n",
       "      <td>J J</td>\n",
       "      <td>0007-0963</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>A serum haemagglutinating property dependent u...</td>\n",
       "      <td>A serum agglutinin reactive with red cells in ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>British journal of haematology</td>\n",
       "      <td>1975 Jan</td>\n",
       "      <td>M L</td>\n",
       "      <td>W L</td>\n",
       "      <td>0007-1048</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed25n0001.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PMID                                              Title  \\\n",
       "22   24  Influence of a new virostatic compound on the ...   \n",
       "23   23  Effect of etafenone on total and regional myoc...   \n",
       "24   25  Pharmacological properties of new neuroleptic ...   \n",
       "29   30  Lysosomal hydrolases of the epidermis. I. Glyc...   \n",
       "31   32  A serum haemagglutinating property dependent u...   \n",
       "\n",
       "                                         AbstractText Language  \\\n",
       "22  The virostatic compound N,N-diethyl-4-[2-(2-ox...      eng   \n",
       "23  The distribution of blood flow to the subendoc...      eng   \n",
       "24  RMI 61 140, RMI 61 144 and RMI 61 280 are newl...      eng   \n",
       "29  Seven distinct glycosidases (EC 3.2) have been...      eng   \n",
       "31  A serum agglutinin reactive with red cells in ...      eng   \n",
       "\n",
       "                               Journal      Date NameFirstAuthor  \\\n",
       "22              Arzneimittel-Forschung  1975 Sep               H   \n",
       "23              Arzneimittel-Forschung  1975 Sep               H   \n",
       "24              Arzneimittel-Forschung  1975 Sep               L   \n",
       "29  The British journal of dermatology  1975 Jul             P D   \n",
       "31      British journal of haematology  1975 Jan             M L   \n",
       "\n",
       "   NameLastAuthor       ISSN AffiliationFirstAuthor AffiliationLastAuthor  \\\n",
       "22              G  0004-4172                                                \n",
       "23              W  0004-4172                                                \n",
       "24              A  0004-4172                                                \n",
       "29            J J  0007-0963                                                \n",
       "31            W L  0007-1048                                                \n",
       "\n",
       "             filename  \n",
       "22  pubmed25n0001.xml  \n",
       "23  pubmed25n0001.xml  \n",
       "24  pubmed25n0001.xml  \n",
       "29  pubmed25n0001.xml  \n",
       "31  pubmed25n0001.xml  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_2025_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 45.5 s, total: 2min 20s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save intermediate dataframe\n",
    "\n",
    "clean_2025_df.to_pickle(berenslab_data_path / \"clean_2025_df_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label\n",
    "Generate labels based on the journal title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color_legend = {\n",
    "    \"cancer\": \"black\",\n",
    "    \"neuroscience\": \"#aeaa00\",\n",
    "    \"cardiology\": \"#1CE6FF\",\n",
    "    \"ecology\": \"#FF34FF\",\n",
    "    \"bioinformatics\": \"#FF4A46\",\n",
    "    \"chemistry\": \"#008941\",\n",
    "    \"surgery\": \"#006FA6\",\n",
    "    \"environment\": \"#0089A3\",\n",
    "    \"material\": \"#0000A6\",\n",
    "    \"microbiology\": \"#B79762\",\n",
    "    \"pediatric\": \"#004D43\",\n",
    "    \"immunology\": \"#8FB0FF\",\n",
    "    \"psychology\": \"#5A0007\",\n",
    "    \"psychiatry\": \"#BA0900\",\n",
    "    \"genetics\": \"#1B4400\",\n",
    "    \"nutrition\": \"#4FC601\",\n",
    "    \"veterinary\": \"#3B5DFF\",\n",
    "    \"engineering\": \"#00C2A0\",\n",
    "    \"education\": \"#549E79\",\n",
    "    \"physics\": \"#BC23FF\",\n",
    "    \"optics\": \"#C895C5\",\n",
    "    \"nursing\": \"#FF2F80\",\n",
    "    \"neurology\": \"#009271\",\n",
    "    \"radiology\": \"#00FECF\",\n",
    "    \"ophthalmology\": \"#A4E804\",\n",
    "    \"gynecology\": \"#FFB500\",\n",
    "    \"rehabilitation\": \"#6B002C\",\n",
    "    \"pathology\": \"#FF9408\",\n",
    "    \"anesthesiology\": \"#CC0744\",\n",
    "    \"dermatology\": \"#D790FF\",\n",
    "    \"pharmacology\": \"#5B4534\",\n",
    "    \"physiology\": \"#E83000\",\n",
    "    \"virology\": \"#6F0062\",\n",
    "    \"biochemistry\": \"#b65141\",\n",
    "    \"computation\": \"#C20078\",\n",
    "    \"infectious\": \"#7A4900\",\n",
    "    \"healthcare\": \"#FF90C9\",\n",
    "    \"ethics\": \"#6508ba\",\n",
    "    \"dentistry\": \"#8e4d8a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 17s, sys: 21.4 s, total: 10min 38s\n",
      "Wall time: 10min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_2025, _ = improved_coloring(clean_2025_df.Journal, label_color_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country\n",
    "Extract first author's affiliation country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = [\n",
    "    \"Afghanistan\",\n",
    "    \"Albania\",\n",
    "    \"Algeria\",\n",
    "    \"Andorra\",\n",
    "    \"Angola\",\n",
    "    \"Antigua and Barbuda\",\n",
    "    \"Argentina\",\n",
    "    \"Armenia\",\n",
    "    \"Australia\",\n",
    "    \"Austria\",\n",
    "    \"Azerbaijan\",\n",
    "    \"Bahamas\",\n",
    "    \"Bahrain\",\n",
    "    \"Bangladesh\",\n",
    "    \"Barbados\",\n",
    "    \"Belarus\",\n",
    "    \"Belgium\",\n",
    "    \"Belize\",\n",
    "    \"Benin\",\n",
    "    \"Bhutan\",\n",
    "    \"Bolivia\",\n",
    "    \"Bosnia and Herzegovina\",\n",
    "    \"Botswana\",\n",
    "    \"Brazil\",\n",
    "    \"Brunei\",\n",
    "    \"Bulgaria\",\n",
    "    \"Burkina Faso\",\n",
    "    \"Burundi\",\n",
    "    \"Cabo Verde\",\n",
    "    \"Cambodia\",\n",
    "    \"Cameroon\",\n",
    "    \"Canada\",\n",
    "    \"Central African Republic\",\n",
    "    \"Chad\",\n",
    "    \"Chile\",\n",
    "    \"China\",\n",
    "    \"Colombia\",\n",
    "    \"Comoros\",\n",
    "    \"Democratic Republic of the Congo\",\n",
    "    \"Republic of the Congo\",\n",
    "    \"Costa Rica\",\n",
    "    \"Côte d’Ivoire\",\n",
    "    \"Croatia\",\n",
    "    \"Cuba\",\n",
    "    \"Cyprus\",\n",
    "    \"Czech Republic\",\n",
    "    \"Denmark\",\n",
    "    \"Djibouti\",\n",
    "    \"Dominica\",\n",
    "    \"Dominican Republic\",\n",
    "    \"East Timor\",\n",
    "    \"Ecuador\",\n",
    "    \"Egypt\",\n",
    "    \"El Salvador\",\n",
    "    \"Equatorial Guinea\",\n",
    "    \"Eritrea\",\n",
    "    \"Estonia\",\n",
    "    \"Eswatini\",\n",
    "    \"Ethiopia\",\n",
    "    \"Fiji\",\n",
    "    \"Finland\",\n",
    "    \"France\",\n",
    "    \"Gabon\",\n",
    "    \"Gambia\",\n",
    "    \"Georgia\",\n",
    "    \"Germany\",\n",
    "    \"Ghana\",\n",
    "    \"Greece\",\n",
    "    \"Grenada\",\n",
    "    \"Guatemala\",\n",
    "    \"Guinea\",\n",
    "    \"Guinea-Bissau\",\n",
    "    \"Guyana\",\n",
    "    \"Haiti\",\n",
    "    \"Honduras\",\n",
    "    \"Hungary\",\n",
    "    \"Iceland\",\n",
    "    \"India\",\n",
    "    \"Indonesia\",\n",
    "    \"Iran\",\n",
    "    \"Iraq\",\n",
    "    \"Ireland\",\n",
    "    \"Israel\",\n",
    "    \"Italy\",\n",
    "    \"Jamaica\",\n",
    "    \"Japan\",\n",
    "    \"Jordan\",\n",
    "    \"Kazakhstan\",\n",
    "    \"Kenya\",\n",
    "    \"Kiribati\",\n",
    "    \"North Korea\",\n",
    "    \"South Korea\",\n",
    "    \"Kosovo\",\n",
    "    \"Kuwait\",\n",
    "    \"Kyrgyzstan\",\n",
    "    \"Laos\",\n",
    "    \"Latvia\",\n",
    "    \"Lebanon\",\n",
    "    \"Nicaragua\",\n",
    "    \"Niger\",\n",
    "    \"Nigeria\",\n",
    "    \"North Macedonia\",\n",
    "    \"Norway\",\n",
    "    \"Oman\",\n",
    "    \"Pakistan\",\n",
    "    \"Palau\",\n",
    "    \"Panama\",\n",
    "    \"Papua New Guinea\",\n",
    "    \"Paraguay\",\n",
    "    \"Peru\",\n",
    "    \"Philippines\",\n",
    "    \"Poland\",\n",
    "    \"Portugal\",\n",
    "    \"Qatar\",\n",
    "    \"Romania\",\n",
    "    \"Russia\",\n",
    "    \"Rwanda\",\n",
    "    \"Saint Kitts and Nevis\",\n",
    "    \"Saint Lucia\",\n",
    "    \"Saint Vincent and the Grenadines\",\n",
    "    \"Samoa\",\n",
    "    \"San Marino\",\n",
    "    \"Sao Tome and Principe\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"Senegal\",\n",
    "    \"Serbia\",\n",
    "    \"Seychelles\",\n",
    "    \"Sierra Leone\",\n",
    "    \"Singapore\",\n",
    "    \"Slovakia\",\n",
    "    \"Slovenia\",\n",
    "    \"Solomon Islands\",\n",
    "    \"Somalia\",\n",
    "    \"South Africa\",\n",
    "    \"Spain\",\n",
    "    \"Sri Lanka\",\n",
    "    \"Sudan\",\n",
    "    \"South Sudan\",\n",
    "    \"Suriname\",\n",
    "    \"Sweden\",\n",
    "    \"Switzerland\",\n",
    "    \"Syria\",\n",
    "    \"Taiwan\",\n",
    "    \"Tajikistan\",\n",
    "    \"Tanzania\",\n",
    "    \"Thailand\",\n",
    "    \"Togo\",\n",
    "    \"Tonga\",\n",
    "    \"Trinidad and Tobago\",\n",
    "    \"Tunisia\",\n",
    "    \"Turkey\",\n",
    "    \"Turkmenistan\",\n",
    "    \"Tuvalu\",\n",
    "    \"Uganda\",\n",
    "    \"Ukraine\",\n",
    "    \"United Arab Emirates\",\n",
    "    \"United Kingdom\",\n",
    "    \"United States\",\n",
    "    \"Uruguay\",\n",
    "    \"Uzbekistan\",\n",
    "    \"Vanuatu\",\n",
    "    \"Vatican City\",\n",
    "    \"Venezuela\",\n",
    "    \"Vietnam\",\n",
    "    \"Yemen\",\n",
    "    \"Zambia\",\n",
    "    \"Zimbabwe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_countries = dict(zip(all_countries, np.arange(1, len(all_countries) + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 24s, sys: 51.2 s, total: 50min 15s\n",
      "Wall time: 50min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "countries_first_author_2025, _ = mapping_countries(\n",
    "    clean_2025_df.AffiliationFirstAuthor, dict_countries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of process_pubmed_utils failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/process_pubmed_utils.py\", line 4, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "all_states = [\n",
    "    \"Alabama\",\n",
    "    \"Alaska\",\n",
    "    \"Arizona\",\n",
    "    \"Arkansas\",\n",
    "    \"California\",\n",
    "    \"Colorado\",\n",
    "    \"Connecticut\",\n",
    "    \"Delaware\",\n",
    "    \"Florida\",\n",
    "    \"Georgia\",\n",
    "    \"Hawaii\",\n",
    "    \"Idaho\",\n",
    "    \"Illinois\",\n",
    "    \"Indiana\",\n",
    "    \"Iowa\",\n",
    "    \"Kansas\",\n",
    "    \"Kentucky\",\n",
    "    \"Louisiana\",\n",
    "    \"Maine\",\n",
    "    \"Maryland\",\n",
    "    \"Massachusetts\",\n",
    "    \"Michigan\",\n",
    "    \"Minnesota\",\n",
    "    \"Mississippi\",\n",
    "    \"Missouri\",\n",
    "    \"Montana\",\n",
    "    \"Nebraska\",\n",
    "    \"Nevada\",\n",
    "    \"New Hampshire\",\n",
    "    \"New Jersey\",\n",
    "    \"New Mexico\",\n",
    "    \"New York\",\n",
    "    \"North Carolina\",\n",
    "    \"North Dakota\",\n",
    "    \"Ohio\",\n",
    "    \"Oklahoma\",\n",
    "    \"Oregon\",\n",
    "    \"Pennsylvania\",\n",
    "    \"Rhode Island\",\n",
    "    \"South Carolina\",\n",
    "    \"South Dakota\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"Utah\",\n",
    "    \"Vermont\",\n",
    "    \"Virginia\",\n",
    "    \"Washington\",\n",
    "    \"West Virginia\",\n",
    "    \"Wisconsin\",\n",
    "    \"Wyoming\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_states = dict(zip(all_states, np.arange(1, len(all_states) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 18s, sys: 15.2 s, total: 14min 33s\n",
      "Wall time: 14min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_usa_states_first_author_2025, _ = mapping_states(\n",
    "    clean_2025_df.AffiliationFirstAuthor, dict_all_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct USA country with states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_first_author_2025_usa_corrected = np.where(\n",
    "    labels_usa_states_first_author_2025 != \"unknown\",\n",
    "    \"United States\",\n",
    "    countries_first_author_2025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of US papers before correcting 19.12575307810141\n",
      "Percentage of US papers after correcting 23.899611156864236\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of US papers before correcting\",\n",
    "    np.sum(countries_first_author_2025 == \"United States\")\n",
    "    / countries_first_author_2025.shape[0]\n",
    "    * 100,\n",
    ")\n",
    "print(\n",
    "    \"Percentage of US papers after correcting\",\n",
    "    np.sum(countries_first_author_2025_usa_corrected == \"United States\")\n",
    "    / countries_first_author_2025.shape[0]\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook we use the `gender` R package. You can install them in R via comannd `install.packages(\"gender\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "clean_2025_df = pd.read_pickle(berenslab_data_path / \"clean_2025_df_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate first name lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_first_author = clean_2025_df.NameFirstAuthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentge of no names:  0.3543157445911083\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentge of no names: \",\n",
    "    np.sum(name_first_author == \"\") / len(name_first_author) * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.96 s, sys: 114 ms, total: 4.07 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_first_author = [\n",
    "    elem.split()[0] if elem != \"\" else elem for elem in name_first_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 12.7 ms, total: 2.53 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_first_author = [\n",
    "    elem.split(\"-\")[0] if elem != \"\" else elem\n",
    "    for elem in sliced_name_first_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 962 ms, sys: 7.6 ms, total: 970 ms\n",
      "Wall time: 971 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sliced_name_first_author = [len(x) for x in sliced_name_first_author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of names that are just initials:  29.3588957713999\n"
     ]
    }
   ],
   "source": [
    "n_initials = len(\n",
    "    np.array(len_sliced_name_first_author)[\n",
    "        np.array(len_sliced_name_first_author) == 1\n",
    "    ]\n",
    ")\n",
    "n_total_papers = len(np.array(len_sliced_name_first_author))\n",
    "print(\n",
    "    \"Percentage of names that are just initials: \",\n",
    "    n_initials / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of papers with missing names:  0.35466629693467766\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of papers with missing names: \",\n",
    "    np.sum(np.array(sliced_name_first_author) == \"\")\n",
    "    / len(sliced_name_first_author)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing names:  88021\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of missing names: \",\n",
    "    len(\n",
    "        np.array(sliced_name_first_author)[\n",
    "            np.array(sliced_name_first_author) == \"\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 591 ms, total: 4.03 s\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_name_first_author = np.where(\n",
    "    np.array(len_sliced_name_first_author) == 1, \"\", sliced_name_first_author\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of initials + missing names:  29.713562068334582\n"
     ]
    }
   ],
   "source": [
    "n_initials_and_missing = len(\n",
    "    np.array(filtered_name_first_author)[\n",
    "        np.array(filtered_name_first_author) == \"\"\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Percentage of initials + missing names: \",\n",
    "    n_initials_and_missing / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_last_author = clean_2025_df.NameLastAuthor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.06 s, sys: 211 ms, total: 4.27 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_last_author = [\n",
    "    elem.split()[0] if elem != \"\" else elem for elem in name_last_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 10.7 ms, total: 2.54 s\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_last_author = [\n",
    "    elem.split(\"-\")[0] if elem != \"\" else elem\n",
    "    for elem in sliced_name_last_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 996 ms, sys: 6.58 ms, total: 1 s\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sliced_name_last_author = [len(x) for x in sliced_name_last_author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of names that are just initials:  29.753424302069426\n"
     ]
    }
   ],
   "source": [
    "n_initials = len(\n",
    "    np.array(len_sliced_name_last_author)[\n",
    "        np.array(len_sliced_name_last_author) == 1\n",
    "    ]\n",
    ")\n",
    "n_total_papers = len(np.array(len_sliced_name_last_author))\n",
    "print(\n",
    "    \"Percentage of names that are just initials: \",\n",
    "    n_initials / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing names:  282010\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of missing names: \",\n",
    "    len(\n",
    "        np.array(sliced_name_last_author)[\n",
    "            np.array(sliced_name_last_author) == \"\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 614 ms, total: 4.21 s\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_name_last_author = np.where(\n",
    "    np.array(len_sliced_name_last_author) == 1, \"\", sliced_name_last_author\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of initials + missing names:  30.8897377090808\n"
     ]
    }
   ],
   "source": [
    "n_initials_and_missing = len(\n",
    "    np.array(filtered_name_last_author)[\n",
    "        np.array(filtered_name_last_author) == \"\"\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Percentage of initials + missing names: \",\n",
    "    n_initials_and_missing / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>BoolVector with 1 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "                   1\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.BoolVector object at 0x7fd31b070640> [RTYPES.LGLSXP]\n",
       "R classes: ('logical',)\n",
       "[       1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(gender)\n",
    "%R require(tibble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_year = clean_2025_df.Date.str.extract(\"([12]\\d\\d\\d)\").values.astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817972</th>\n",
       "      <td>2025</td>\n",
       "      <td>Shu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817973</th>\n",
       "      <td>2025</td>\n",
       "      <td>NokI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817974</th>\n",
       "      <td>2025</td>\n",
       "      <td>Heriberto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817975</th>\n",
       "      <td>2025</td>\n",
       "      <td>Shahab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817976</th>\n",
       "      <td>2025</td>\n",
       "      <td>Daniele</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24817977 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Years      Names\n",
       "0          1975           \n",
       "1          1975           \n",
       "2          1975           \n",
       "3          1975           \n",
       "4          1975           \n",
       "...         ...        ...\n",
       "24817972   2025        Shu\n",
       "24817973   2025       NokI\n",
       "24817974   2025  Heriberto\n",
       "24817975   2025     Shahab\n",
       "24817976   2025    Daniele\n",
       "\n",
       "[24817977 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I initialize a dataframe where I will store year, name and gender\n",
    "# This will be the dataframe `year_name_gender_first_author_df'\n",
    "\n",
    "df_subset = pd.DataFrame(\n",
    "    {\"Years\": date_year, \"Names\": filtered_name_first_author}\n",
    ")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  1808\n",
      "Year:  1876\n",
      "Year:  1881\n",
      "Year:  1883\n",
      "Year:  1891\n",
      "Year:  1896\n",
      "Year:  1897\n",
      "Year:  1898\n",
      "Year:  1899\n",
      "Year:  1900\n",
      "Year:  1901\n",
      "Year:  1902\n",
      "Year:  1903\n",
      "Year:  1905\n",
      "Year:  1906\n",
      "Year:  1907\n",
      "Year:  1908\n",
      "Year:  1909\n",
      "Year:  1910\n",
      "Year:  1911\n",
      "Year:  1912\n",
      "Year:  1913\n",
      "Year:  1914\n",
      "Year:  1915\n",
      "Year:  1916\n",
      "Year:  1917\n",
      "Year:  1918\n",
      "Year:  1919\n",
      "Year:  1920\n",
      "Year:  1921\n",
      "Year:  1922\n",
      "Year:  1923\n",
      "Year:  1924\n",
      "Year:  1925\n",
      "Year:  1926\n",
      "Year:  1927\n",
      "Year:  1928\n",
      "Year:  1929\n",
      "Year:  1930\n",
      "Year:  1931\n",
      "Year:  1932\n",
      "Year:  1933\n",
      "Year:  1934\n",
      "Year:  1935\n",
      "Year:  1936\n",
      "Year:  1937\n",
      "Year:  1938\n",
      "Year:  1939\n",
      "Year:  1940\n",
      "Year:  1941\n",
      "Year:  1942\n",
      "Year:  1943\n",
      "Year:  1944\n",
      "Year:  1945\n",
      "Year:  1946\n",
      "Year:  1947\n",
      "Year:  1948\n",
      "Year:  1949\n",
      "Year:  1950\n",
      "Year:  1951\n",
      "Year:  1952\n",
      "Year:  1953\n",
      "Year:  1954\n",
      "Year:  1955\n",
      "Year:  1956\n",
      "Year:  1957\n",
      "Year:  1958\n",
      "Year:  1959\n",
      "Year:  1960\n",
      "Year:  1961\n",
      "Year:  1962\n",
      "Year:  1963\n",
      "Year:  1964\n",
      "Year:  1965\n",
      "Year:  1966\n",
      "Year:  1967\n",
      "Year:  1968\n",
      "Year:  1969\n",
      "Year:  1970\n",
      "Year:  1971\n",
      "Year:  1972\n",
      "Year:  1973\n",
      "Year:  1974\n",
      "Year:  1975\n",
      "Year:  1976\n",
      "Year:  1977\n",
      "Year:  1978\n",
      "Year:  1979\n",
      "Year:  1980\n",
      "Year:  1981\n",
      "Year:  1982\n",
      "Year:  1983\n",
      "Year:  1984\n",
      "Year:  1985\n",
      "Year:  1986\n",
      "Year:  1987\n",
      "Year:  1988\n",
      "Year:  1989\n",
      "Year:  1990\n",
      "Year:  1991\n",
      "Year:  1992\n",
      "Year:  1993\n",
      "Year:  1994\n",
      "Year:  1995\n",
      "Year:  1996\n",
      "Year:  1997\n",
      "Year:  1998\n",
      "Year:  1999\n",
      "Year:  2000\n",
      "Year:  2001\n",
      "Year:  2002\n",
      "Year:  2003\n",
      "Year:  2004\n",
      "Year:  2005\n",
      "Year:  2006\n",
      "Year:  2007\n",
      "Year:  2008\n",
      "Year:  2009\n",
      "Year:  2010\n",
      "Year:  2011\n",
      "Year:  2012\n",
      "Year:  2013\n",
      "Year:  2014\n",
      "Year:  2015\n",
      "Year:  2016\n",
      "Year:  2017\n",
      "Year:  2018\n",
      "Year:  2019\n",
      "Year:  2020\n",
      "Year:  2021\n",
      "Year:  2022\n",
      "Year:  2023\n",
      "Year:  2024\n",
      "Year:  2025\n",
      "Year:  2143\n",
      "CPU times: user 5min 28s, sys: 4.17 s, total: 5min 32s\n",
      "Wall time: 5min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>proportion_male</th>\n",
       "      <th>proportion_female</th>\n",
       "      <th>gender</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chalmers</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edmund</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leigh</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mary</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>female</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>male</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533564</th>\n",
       "      <td>Zuzanna</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533565</th>\n",
       "      <td>Zuzanna</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533566</th>\n",
       "      <td>Zuzu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533567</th>\n",
       "      <td>Zvi</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533568</th>\n",
       "      <td>Adham</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10533569 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  proportion_male  proportion_female  gender  year_min  \\\n",
       "0         Chalmers           1.0000             0.0000    male    1930.0   \n",
       "1           Edmund           0.9940             0.0060    male    1930.0   \n",
       "2            Leigh           0.7342             0.2658    male    1930.0   \n",
       "3             Mary           0.0056             0.9944  female    1932.0   \n",
       "4              Ben           0.9866             0.0134    male    1933.0   \n",
       "...            ...              ...                ...     ...       ...   \n",
       "10533564   Zuzanna           0.0000             1.0000  female    2012.0   \n",
       "10533565   Zuzanna           0.0000             1.0000  female    2012.0   \n",
       "10533566      Zuzu           0.0000             1.0000  female    2012.0   \n",
       "10533567       Zvi           1.0000             0.0000    male    2012.0   \n",
       "10533568     Adham           1.0000             0.0000    male    2012.0   \n",
       "\n",
       "          year_max  \n",
       "0           1930.0  \n",
       "1           1930.0  \n",
       "2           1930.0  \n",
       "3           1932.0  \n",
       "4           1933.0  \n",
       "...            ...  \n",
       "10533564    2012.0  \n",
       "10533565    2012.0  \n",
       "10533566    2012.0  \n",
       "10533567    2012.0  \n",
       "10533568    2012.0  \n",
       "\n",
       "[10533569 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# I predict the gender of those names sorting the df by year.\n",
    "# The problem is that the returned df does not have the same dimensions as the original, since not all the papers have names.\n",
    "# Therefore, the next two steps are necessary\n",
    "\n",
    "gender_prediction_df = pd.DataFrame()\n",
    "unique_years = np.unique(df_subset.Years)\n",
    "\n",
    "for year in unique_years:\n",
    "    print(\"Year: \", year)\n",
    "\n",
    "    df_grouped_year = df_subset.groupby(\"Years\").get_group(year)\n",
    "    df_names = df_grouped_year.Names\n",
    "\n",
    "    # cases for years outside interval\n",
    "    if year <= 1930:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 1930, method = \"ssa\")\n",
    "\n",
    "    if year >= 2012:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 2012, method = \"ssa\")\n",
    "\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        %R library(gender)\n",
    "        %R -i df_names -i year -o result result = gender(df_names, years = year, method = \"ssa\")\n",
    "\n",
    "    gender_prediction_df = pd.concat(\n",
    "        [gender_prediction_df, result], ignore_index=True\n",
    "    )\n",
    "\n",
    "gender_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 s, sys: 214 ms, total: 50.6 s\n",
      "Wall time: 50.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([np.int64(1808), np.int64(1876), np.int64(1881), np.int64(1883), np.int64(1891), np.int64(1896), np.int64(1897), np.int64(1898), np.int64(1899), np.int64(1900), np.int64(1901), np.int64(1902), np.int64(1903), np.int64(1905), np.int64(1906), np.int64(1907), np.int64(1908), np.int64(1909), np.int64(1910), np.int64(1911), np.int64(1912), np.int64(1913), np.int64(1914), np.int64(1915), np.int64(1916), np.int64(1917), np.int64(1918), np.int64(1919), np.int64(1920), np.int64(1921), np.int64(1922), np.int64(1923), np.int64(1924), np.int64(1925), np.int64(1926), np.int64(1927), np.int64(1928), np.int64(1929), np.int64(1930), np.int64(1931), np.int64(1932), np.int64(1933), np.int64(1934), np.int64(1935), np.int64(1936), np.int64(1937), np.int64(1938), np.int64(1939), np.int64(1940), np.int64(1941), np.int64(1942), np.int64(1943), np.int64(1944), np.int64(1945), np.int64(1946), np.int64(1947), np.int64(1948), np.int64(1949), np.int64(1950), np.int64(1951), np.int64(1952), np.int64(1953), np.int64(1954), np.int64(1955), np.int64(1956), np.int64(1957), np.int64(1958), np.int64(1959), np.int64(1960), np.int64(1961), np.int64(1962), np.int64(1963), np.int64(1964), np.int64(1965), np.int64(1966), np.int64(1967), np.int64(1968), np.int64(1969), np.int64(1970), np.int64(1971), np.int64(1972), np.int64(1973), np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2143)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# In here I am creating a dictionary that has a map name-gender for every year, based on the predictions from the dataframe above (because they are year dependent).\n",
    "# I do some tricks to create mappings for also years that were not predicted, and years outside the available `ssa' intervals (<1930, >2012)\n",
    "\n",
    "unique_predicted_years = np.unique(gender_prediction_df[\"year_min\"])\n",
    "gender_maps_years = {}\n",
    "for year in unique_years:\n",
    "    if year >= 2012:\n",
    "        eff_year = 2012\n",
    "    if year <= 1930:\n",
    "        eff_year = 1930\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        eff_year = year\n",
    "\n",
    "    if eff_year not in unique_predicted_years:\n",
    "        closest_year = unique_predicted_years[\n",
    "            (unique_predicted_years - eff_year).argmin()\n",
    "        ]\n",
    "\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(closest_year)\n",
    "\n",
    "    else:\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(eff_year)\n",
    "\n",
    "    gender_map = dict(\n",
    "        zip(\n",
    "            gender_prediction_grouped_year.name,\n",
    "            gender_prediction_grouped_year.gender,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gender_maps_years[year] = gender_map\n",
    "\n",
    "gender_maps_years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1876\n",
      "1881\n",
      "1883\n",
      "1891\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2143\n",
      "CPU times: user 7min 18s, sys: 1.43 s, total: 7min 19s\n",
      "Wall time: 7min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817972</th>\n",
       "      <td>2025</td>\n",
       "      <td>Shu</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817973</th>\n",
       "      <td>2025</td>\n",
       "      <td>NokI</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817974</th>\n",
       "      <td>2025</td>\n",
       "      <td>Heriberto</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817975</th>\n",
       "      <td>2025</td>\n",
       "      <td>Shahab</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817976</th>\n",
       "      <td>2025</td>\n",
       "      <td>Daniele</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24817977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Years      Names   Gender\n",
       "0          1975             unknown\n",
       "1          1975             unknown\n",
       "2          1975             unknown\n",
       "3          1975             unknown\n",
       "4          1975             unknown\n",
       "...         ...        ...      ...\n",
       "24817972   2025        Shu  unknown\n",
       "24817973   2025       NokI  unknown\n",
       "24817974   2025  Heriberto     male\n",
       "24817975   2025     Shahab     male\n",
       "24817976   2025    Daniele   female\n",
       "\n",
       "[24817977 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Now, using the name-gender maps created above, I map the names in the original dataframe (df_subset) to their respective genders, saving them in a new column 'Gender'\n",
    "\n",
    "# here I add a 'Gender' column to the df_subset\n",
    "df_subset[\"Gender\"] = [\"unknown\"] * df_subset.shape[0]\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "\n",
    "    df_subset_year = (\n",
    "        df_subset.groupby(\"Years\")\n",
    "        .get_group(year)\n",
    "        .Names.apply(lambda x: np.vectorize(gender_maps_years[year].get)(x))\n",
    "    )\n",
    "    df_subset_year.rename(\"Gender\", inplace=True)\n",
    "    df_subset.update(df_subset_year)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10624183"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the number of predicted genders matches the length of the df with the predictions above\n",
    "len(df_subset[df_subset.Gender != \"unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save\n",
    "gender_first_author = df_subset.Gender.to_numpy(dtype=str)\n",
    "np.save(variables_path / \"gender_first_author\", gender_first_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817972</th>\n",
       "      <td>2025</td>\n",
       "      <td>Jian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817973</th>\n",
       "      <td>2025</td>\n",
       "      <td>Wenli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817974</th>\n",
       "      <td>2025</td>\n",
       "      <td>Bachir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817975</th>\n",
       "      <td>2025</td>\n",
       "      <td>Mohammad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817976</th>\n",
       "      <td>2025</td>\n",
       "      <td>Fabio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24817977 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Years     Names\n",
       "0          1975          \n",
       "1          1975          \n",
       "2          1975          \n",
       "3          1975          \n",
       "4          1975          \n",
       "...         ...       ...\n",
       "24817972   2025      Jian\n",
       "24817973   2025     Wenli\n",
       "24817974   2025    Bachir\n",
       "24817975   2025  Mohammad\n",
       "24817976   2025     Fabio\n",
       "\n",
       "[24817977 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = pd.DataFrame(\n",
    "    {\"Years\": date_year, \"Names\": filtered_name_last_author}\n",
    ")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1876\n",
      "1881\n",
      "1883\n",
      "1891\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2143\n",
      "CPU times: user 5min 22s, sys: 3.98 s, total: 5min 26s\n",
      "Wall time: 5min 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>proportion_male</th>\n",
       "      <th>proportion_female</th>\n",
       "      <th>gender</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chalmers</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edmund</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leigh</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>male</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mary</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>female</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rose</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>female</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624178</th>\n",
       "      <td>Zuzana</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624179</th>\n",
       "      <td>Zuzana</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624180</th>\n",
       "      <td>Zuzanna</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624181</th>\n",
       "      <td>Zvi</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624182</th>\n",
       "      <td>Zvi</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10624183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  proportion_male  proportion_female  gender  year_min  \\\n",
       "0         Chalmers           1.0000             0.0000    male    1930.0   \n",
       "1           Edmund           0.9940             0.0060    male    1930.0   \n",
       "2            Leigh           0.7342             0.2658    male    1930.0   \n",
       "3             Mary           0.0056             0.9944  female    1932.0   \n",
       "4             Rose           0.0067             0.9933  female    1932.0   \n",
       "...            ...              ...                ...     ...       ...   \n",
       "10624178    Zuzana           0.0000             1.0000  female    2012.0   \n",
       "10624179    Zuzana           0.0000             1.0000  female    2012.0   \n",
       "10624180   Zuzanna           0.0000             1.0000  female    2012.0   \n",
       "10624181       Zvi           1.0000             0.0000    male    2012.0   \n",
       "10624182       Zvi           1.0000             0.0000    male    2012.0   \n",
       "\n",
       "          year_max  \n",
       "0           1930.0  \n",
       "1           1930.0  \n",
       "2           1930.0  \n",
       "3           1932.0  \n",
       "4           1932.0  \n",
       "...            ...  \n",
       "10624178    2012.0  \n",
       "10624179    2012.0  \n",
       "10624180    2012.0  \n",
       "10624181    2012.0  \n",
       "10624182    2012.0  \n",
       "\n",
       "[10624183 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gender_prediction_df = pd.DataFrame()\n",
    "unique_years = np.unique(df_subset.Years)\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "    df_grouped_year = df_subset.groupby(\"Years\").get_group(year)\n",
    "    df_names = df_grouped_year.Names\n",
    "\n",
    "    # cases for years outside interval\n",
    "    if year <= 1930:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 1930, method = \"ssa\")\n",
    "\n",
    "    if year >= 2012:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 2012, method = \"ssa\")\n",
    "\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        %R library(gender)\n",
    "        %R -i df_names -i year -o result result = gender(df_names, years = year, method = \"ssa\")\n",
    "\n",
    "    gender_prediction_df = pd.concat(\n",
    "        [gender_prediction_df, result], ignore_index=True\n",
    "    )\n",
    "\n",
    "gender_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.9 s, sys: 407 ms, total: 51.4 s\n",
      "Wall time: 51.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([np.int64(1808), np.int64(1876), np.int64(1881), np.int64(1883), np.int64(1891), np.int64(1896), np.int64(1897), np.int64(1898), np.int64(1899), np.int64(1900), np.int64(1901), np.int64(1902), np.int64(1903), np.int64(1905), np.int64(1906), np.int64(1907), np.int64(1908), np.int64(1909), np.int64(1910), np.int64(1911), np.int64(1912), np.int64(1913), np.int64(1914), np.int64(1915), np.int64(1916), np.int64(1917), np.int64(1918), np.int64(1919), np.int64(1920), np.int64(1921), np.int64(1922), np.int64(1923), np.int64(1924), np.int64(1925), np.int64(1926), np.int64(1927), np.int64(1928), np.int64(1929), np.int64(1930), np.int64(1931), np.int64(1932), np.int64(1933), np.int64(1934), np.int64(1935), np.int64(1936), np.int64(1937), np.int64(1938), np.int64(1939), np.int64(1940), np.int64(1941), np.int64(1942), np.int64(1943), np.int64(1944), np.int64(1945), np.int64(1946), np.int64(1947), np.int64(1948), np.int64(1949), np.int64(1950), np.int64(1951), np.int64(1952), np.int64(1953), np.int64(1954), np.int64(1955), np.int64(1956), np.int64(1957), np.int64(1958), np.int64(1959), np.int64(1960), np.int64(1961), np.int64(1962), np.int64(1963), np.int64(1964), np.int64(1965), np.int64(1966), np.int64(1967), np.int64(1968), np.int64(1969), np.int64(1970), np.int64(1971), np.int64(1972), np.int64(1973), np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2143)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_predicted_years = np.unique(gender_prediction_df[\"year_min\"])\n",
    "gender_maps_years = {}\n",
    "for year in unique_years:\n",
    "    if year >= 2012:\n",
    "        eff_year = 2012\n",
    "    if year <= 1930:\n",
    "        eff_year = 1930\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        eff_year = year\n",
    "\n",
    "    if eff_year not in unique_predicted_years:\n",
    "        closest_year = unique_predicted_years[\n",
    "            (unique_predicted_years - eff_year).argmin()\n",
    "        ]\n",
    "\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(closest_year)\n",
    "\n",
    "    else:\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(eff_year)\n",
    "\n",
    "    gender_map = dict(\n",
    "        zip(\n",
    "            gender_prediction_grouped_year.name,\n",
    "            gender_prediction_grouped_year.gender,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gender_maps_years[year] = gender_map\n",
    "\n",
    "gender_maps_years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1876\n",
      "1881\n",
      "1883\n",
      "1891\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2143\n",
      "CPU times: user 7min 18s, sys: 1.27 s, total: 7min 19s\n",
      "Wall time: 7min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817972</th>\n",
       "      <td>2025</td>\n",
       "      <td>Jian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817973</th>\n",
       "      <td>2025</td>\n",
       "      <td>Wenli</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817974</th>\n",
       "      <td>2025</td>\n",
       "      <td>Bachir</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817975</th>\n",
       "      <td>2025</td>\n",
       "      <td>Mohammad</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817976</th>\n",
       "      <td>2025</td>\n",
       "      <td>Fabio</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24817977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Years     Names   Gender\n",
       "0          1975            unknown\n",
       "1          1975            unknown\n",
       "2          1975            unknown\n",
       "3          1975            unknown\n",
       "4          1975            unknown\n",
       "...         ...       ...      ...\n",
       "24817972   2025      Jian     male\n",
       "24817973   2025     Wenli  unknown\n",
       "24817974   2025    Bachir  unknown\n",
       "24817975   2025  Mohammad     male\n",
       "24817976   2025     Fabio     male\n",
       "\n",
       "[24817977 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_subset[\"Gender\"] = [\"unknown\"] * df_subset.shape[0]\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "\n",
    "    df_subset_year = (\n",
    "        df_subset.groupby(\"Years\")\n",
    "        .get_group(year)\n",
    "        .Names.apply(lambda x: np.vectorize(gender_maps_years[year].get)(x))\n",
    "    )\n",
    "    df_subset_year.rename(\"Gender\", inplace=True)\n",
    "    df_subset.update(df_subset_year)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10624183"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the number of predicted genders matches the length of the df with the predictions above\n",
    "len(df_subset[df_subset.Gender != \"unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save\n",
    "gender_last_author = df_subset.Gender.to_numpy(dtype=str)\n",
    "np.save(variables_path / \"gender_last_author_2024\", gender_last_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- PMID\n",
    "- abstract\n",
    "- journal\n",
    "- publication year (update also preprocess-and-count bc the year is being extracted there)\n",
    "- label\n",
    "- affiliation country (from the first affiliation of the first author).\n",
    "- inferred gender of first and last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_2025_df[[\"PMID\", \"Title\", \"AbstractText\", \"Journal\", \"Date\"]].copy(\n",
    "    deep=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"] = df.Date.str.extract(\"([12]\\d\\d\\d)\").values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22             1975 Sep\n",
       "23             1975 Sep\n",
       "24             1975 Sep\n",
       "29             1975 Jul\n",
       "31             1975 Jan\n",
       "               ...     \n",
       "38201548    2025 Jan 08\n",
       "38201549    2025 Jan 08\n",
       "38201550       2025 Feb\n",
       "38201551    2025 Jan 07\n",
       "38201552    2025 Jan 07\n",
       "Name: Date, Length: 24817977, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Labels\"] = labels_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Countries\"] = countries_first_author_2025_usa_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InferredGenderFirstAuthor\"] = gender_first_author\n",
    "df[\"InferredGenderLastAuthor\"] = gender_last_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24817977"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"PMID\"], as_index=False).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24814136 new papers\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(df)} new papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>AbstractText</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Year</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Countries</th>\n",
       "      <th>InferredGenderFirstAuthor</th>\n",
       "      <th>InferredGenderLastAuthor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>The amino acid sequence of Neurospora NADP-spe...</td>\n",
       "      <td>The NADP-specific glutamate dehydrogenase of N...</td>\n",
       "      <td>The Biochemical journal</td>\n",
       "      <td>1975</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>A new method for the determination of alpha1-p...</td>\n",
       "      <td>Up until now it has been assumed that the prot...</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>1976</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000017</td>\n",
       "      <td>Development of a short term assay for lymphobl...</td>\n",
       "      <td>Blastic stimulation of lymphocytes by antigens...</td>\n",
       "      <td>Biomedicine / [publiee pour l'A.A.I.C.I.G.]</td>\n",
       "      <td>1976</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000018</td>\n",
       "      <td>Neonatal polycythemia in low birthweight infant.</td>\n",
       "      <td>74 low birthweight infants haematologic findin...</td>\n",
       "      <td>Biomedicine / [publiee pour l'A.A.I.C.I.G.]</td>\n",
       "      <td>1976</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000019</td>\n",
       "      <td>Is there evidence for subclasses of chronic ly...</td>\n",
       "      <td>Various clinical and biological parameters wer...</td>\n",
       "      <td>Biomedicine / [publiee pour l'A.A.I.C.I.G.]</td>\n",
       "      <td>1976</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PMID                                              Title  \\\n",
       "0     1000  The amino acid sequence of Neurospora NADP-spe...   \n",
       "1    10000  A new method for the determination of alpha1-p...   \n",
       "2  1000017  Development of a short term assay for lymphobl...   \n",
       "3  1000018   Neonatal polycythemia in low birthweight infant.   \n",
       "4  1000019  Is there evidence for subclasses of chronic ly...   \n",
       "\n",
       "                                        AbstractText  \\\n",
       "0  The NADP-specific glutamate dehydrogenase of N...   \n",
       "1  Up until now it has been assumed that the prot...   \n",
       "2  Blastic stimulation of lymphocytes by antigens...   \n",
       "3  74 low birthweight infants haematologic findin...   \n",
       "4  Various clinical and biological parameters wer...   \n",
       "\n",
       "                                       Journal  Year     Labels Countries  \\\n",
       "0                      The Biochemical journal  1975  unlabeled   unknown   \n",
       "1                Biochimica et biophysica acta  1976  unlabeled   unknown   \n",
       "2  Biomedicine / [publiee pour l'A.A.I.C.I.G.]  1976  unlabeled   unknown   \n",
       "3  Biomedicine / [publiee pour l'A.A.I.C.I.G.]  1976  unlabeled   unknown   \n",
       "4  Biomedicine / [publiee pour l'A.A.I.C.I.G.]  1976  unlabeled   unknown   \n",
       "\n",
       "  InferredGenderFirstAuthor InferredGenderLastAuthor  \n",
       "0                   unknown                  unknown  \n",
       "1                   unknown                  unknown  \n",
       "2                   unknown                  unknown  \n",
       "3                   unknown                  unknown  \n",
       "4                   unknown                  unknown  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24814136, 9)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 29s, sys: 24.3 s, total: 35min 53s\n",
      "Wall time: 36min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "compression_opts = dict(method=\"zip\", archive_name=\"pubmed_baseline_2025.csv\")\n",
    "\n",
    "df.to_csv(\n",
    "    berenslab_data_path / \"pubmed_baseline_2025.zip\",\n",
    "    index=False,\n",
    "    compression=compression_opts,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
