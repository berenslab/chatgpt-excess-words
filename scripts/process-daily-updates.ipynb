{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpfs01/berens/user/rgonzalesmarquez', '/.pyenv/versions/miniconda3-latest/lib/python311.zip', '/.pyenv/versions/miniconda3-latest/lib/python3.11', '/.pyenv/versions/miniconda3-latest/lib/python3.11/lib-dynload', '', '/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages', '/gpfs01/berens/user/rgonzalesmarquez/phd/text-embeddings', '/gpfs01/berens/user/rgonzalesmarquez/phd/pubmed-landscape', '/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages', '/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/', '/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/']\n"
     ]
    }
   ],
   "source": [
    "# FIX VSCODE PATH PROBLEM -- DELETE AFTER\n",
    "import sys\n",
    "\n",
    "# add path\n",
    "sys.path.append(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts/\"\n",
    ")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from daily_updates_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../figures\")\n",
    "data_path = Path(\"../data\")\n",
    "berenslab_data_path = Path(\"/gpfs01/berens/data/data/pubmed_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "\n",
    "nb_path = Path(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/chatgpt-excess-words/scripts\"\n",
    ")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract from PubMed's metadata `.xml` files the following:\n",
    "- PubMed ID\n",
    "- title\n",
    "- abstract\n",
    "- language\n",
    "- journal title\n",
    "- ISSN\n",
    "- publication date\n",
    "- (first and last) author first names\n",
    "- (first and last) author Affiliations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024 daily updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed24n1220.xml\n",
      "pubmed24n1221.xml\n",
      "pubmed24n1222.xml\n",
      "pubmed24n1223.xml\n",
      "pubmed24n1224.xml\n",
      "pubmed24n1225.xml\n",
      "pubmed24n1226.xml\n",
      "pubmed24n1227.xml\n",
      "pubmed24n1228.xml\n",
      "pubmed24n1229.xml\n",
      "pubmed24n1230.xml\n",
      "pubmed24n1231.xml\n",
      "pubmed24n1232.xml\n",
      "pubmed24n1233.xml\n",
      "pubmed24n1234.xml\n",
      "pubmed24n1235.xml\n",
      "pubmed24n1236.xml\n",
      "pubmed24n1237.xml\n",
      "pubmed24n1238.xml\n",
      "pubmed24n1239.xml\n",
      "pubmed24n1240.xml\n",
      "pubmed24n1241.xml\n",
      "pubmed24n1242.xml\n",
      "pubmed24n1243.xml\n",
      "pubmed24n1244.xml\n",
      "pubmed24n1245.xml\n",
      "pubmed24n1246.xml\n",
      "pubmed24n1247.xml\n",
      "pubmed24n1248.xml\n",
      "pubmed24n1249.xml\n",
      "pubmed24n1250.xml\n",
      "pubmed24n1251.xml\n",
      "pubmed24n1252.xml\n",
      "pubmed24n1253.xml\n",
      "pubmed24n1254.xml\n",
      "pubmed24n1255.xml\n",
      "pubmed24n1256.xml\n",
      "pubmed24n1257.xml\n",
      "pubmed24n1258.xml\n",
      "pubmed24n1259.xml\n",
      "pubmed24n1260.xml\n",
      "pubmed24n1261.xml\n",
      "pubmed24n1262.xml\n",
      "pubmed24n1263.xml\n",
      "pubmed24n1264.xml\n",
      "pubmed24n1265.xml\n",
      "pubmed24n1266.xml\n",
      "pubmed24n1267.xml\n",
      "pubmed24n1268.xml\n",
      "pubmed24n1269.xml\n",
      "pubmed24n1270.xml\n",
      "pubmed24n1271.xml\n",
      "pubmed24n1272.xml\n",
      "pubmed24n1273.xml\n",
      "pubmed24n1274.xml\n",
      "pubmed24n1275.xml\n",
      "pubmed24n1276.xml\n",
      "pubmed24n1277.xml\n",
      "pubmed24n1278.xml\n",
      "pubmed24n1279.xml\n",
      "pubmed24n1280.xml\n",
      "pubmed24n1281.xml\n",
      "pubmed24n1282.xml\n",
      "pubmed24n1283.xml\n",
      "pubmed24n1284.xml\n",
      "pubmed24n1285.xml\n",
      "pubmed24n1286.xml\n",
      "pubmed24n1287.xml\n",
      "pubmed24n1288.xml\n",
      "pubmed24n1289.xml\n",
      "pubmed24n1290.xml\n",
      "pubmed24n1291.xml\n",
      "pubmed24n1292.xml\n",
      "pubmed24n1293.xml\n",
      "pubmed24n1294.xml\n",
      "pubmed24n1295.xml\n",
      "pubmed24n1296.xml\n",
      "pubmed24n1297.xml\n",
      "pubmed24n1298.xml\n",
      "pubmed24n1299.xml\n",
      "pubmed24n1300.xml\n",
      "pubmed24n1301.xml\n",
      "pubmed24n1302.xml\n",
      "pubmed24n1303.xml\n",
      "pubmed24n1304.xml\n",
      "pubmed24n1305.xml\n",
      "pubmed24n1306.xml\n",
      "pubmed24n1307.xml\n",
      "pubmed24n1308.xml\n",
      "pubmed24n1309.xml\n",
      "pubmed24n1310.xml\n",
      "pubmed24n1311.xml\n",
      "pubmed24n1312.xml\n",
      "pubmed24n1313.xml\n",
      "pubmed24n1314.xml\n",
      "pubmed24n1315.xml\n",
      "pubmed24n1316.xml\n",
      "pubmed24n1317.xml\n",
      "pubmed24n1318.xml\n",
      "pubmed24n1319.xml\n",
      "pubmed24n1320.xml\n",
      "pubmed24n1321.xml\n",
      "pubmed24n1322.xml\n",
      "pubmed24n1323.xml\n",
      "pubmed24n1324.xml\n",
      "pubmed24n1325.xml\n",
      "pubmed24n1326.xml\n",
      "pubmed24n1327.xml\n",
      "pubmed24n1328.xml\n",
      "pubmed24n1329.xml\n",
      "pubmed24n1330.xml\n",
      "pubmed24n1331.xml\n",
      "pubmed24n1332.xml\n",
      "pubmed24n1333.xml\n",
      "pubmed24n1334.xml\n",
      "pubmed24n1335.xml\n",
      "pubmed24n1336.xml\n",
      "pubmed24n1337.xml\n",
      "pubmed24n1338.xml\n",
      "pubmed24n1339.xml\n",
      "pubmed24n1340.xml\n",
      "pubmed24n1341.xml\n",
      "pubmed24n1342.xml\n",
      "pubmed24n1343.xml\n",
      "pubmed24n1344.xml\n",
      "pubmed24n1345.xml\n",
      "pubmed24n1346.xml\n",
      "pubmed24n1347.xml\n",
      "pubmed24n1348.xml\n",
      "pubmed24n1349.xml\n",
      "pubmed24n1350.xml\n",
      "pubmed24n1351.xml\n",
      "pubmed24n1352.xml\n",
      "pubmed24n1353.xml\n",
      "pubmed24n1354.xml\n",
      "pubmed24n1355.xml\n",
      "pubmed24n1356.xml\n",
      "pubmed24n1357.xml\n",
      "pubmed24n1358.xml\n",
      "pubmed24n1359.xml\n",
      "pubmed24n1360.xml\n",
      "pubmed24n1361.xml\n",
      "pubmed24n1362.xml\n",
      "pubmed24n1363.xml\n",
      "pubmed24n1364.xml\n",
      "pubmed24n1365.xml\n",
      "pubmed24n1366.xml\n",
      "pubmed24n1367.xml\n",
      "pubmed24n1368.xml\n",
      "pubmed24n1369.xml\n",
      "pubmed24n1370.xml\n",
      "pubmed24n1371.xml\n",
      "pubmed24n1372.xml\n",
      "pubmed24n1373.xml\n",
      "pubmed24n1374.xml\n",
      "pubmed24n1375.xml\n",
      "pubmed24n1376.xml\n",
      "pubmed24n1377.xml\n",
      "pubmed24n1378.xml\n",
      "pubmed24n1379.xml\n",
      "pubmed24n1380.xml\n",
      "pubmed24n1381.xml\n",
      "pubmed24n1382.xml\n",
      "pubmed24n1383.xml\n",
      "pubmed24n1384.xml\n",
      "pubmed24n1385.xml\n",
      "pubmed24n1386.xml\n",
      "pubmed24n1387.xml\n",
      "pubmed24n1388.xml\n",
      "pubmed24n1389.xml\n",
      "pubmed24n1390.xml\n",
      "pubmed24n1391.xml\n",
      "pubmed24n1392.xml\n",
      "pubmed24n1393.xml\n",
      "pubmed24n1394.xml\n",
      "pubmed24n1395.xml\n",
      "pubmed24n1396.xml\n",
      "pubmed24n1397.xml\n",
      "pubmed24n1398.xml\n",
      "pubmed24n1399.xml\n",
      "pubmed24n1400.xml\n",
      "pubmed24n1401.xml\n",
      "pubmed24n1402.xml\n",
      "pubmed24n1403.xml\n",
      "pubmed24n1404.xml\n",
      "pubmed24n1405.xml\n",
      "pubmed24n1406.xml\n",
      "pubmed24n1407.xml\n",
      "pubmed24n1408.xml\n",
      "pubmed24n1409.xml\n",
      "pubmed24n1410.xml\n",
      "pubmed24n1411.xml\n",
      "pubmed24n1412.xml\n",
      "pubmed24n1413.xml\n",
      "pubmed24n1414.xml\n",
      "pubmed24n1415.xml\n",
      "pubmed24n1416.xml\n",
      "pubmed24n1417.xml\n",
      "pubmed24n1418.xml\n",
      "pubmed24n1419.xml\n",
      "pubmed24n1420.xml\n",
      "pubmed24n1421.xml\n",
      "pubmed24n1422.xml\n",
      "pubmed24n1423.xml\n",
      "pubmed24n1424.xml\n",
      "pubmed24n1425.xml\n",
      "pubmed24n1426.xml\n",
      "pubmed24n1427.xml\n",
      "pubmed24n1428.xml\n",
      "pubmed24n1429.xml\n",
      "pubmed24n1430.xml\n",
      "pubmed24n1431.xml\n",
      "pubmed24n1432.xml\n",
      "pubmed24n1433.xml\n",
      "pubmed24n1434.xml\n",
      "pubmed24n1435.xml\n",
      "pubmed24n1436.xml\n",
      "pubmed24n1437.xml\n",
      "pubmed24n1438.xml\n",
      "pubmed24n1439.xml\n",
      "pubmed24n1440.xml\n",
      "pubmed24n1441.xml\n",
      "pubmed24n1442.xml\n",
      "pubmed24n1443.xml\n",
      "pubmed24n1444.xml\n",
      "pubmed24n1445.xml\n",
      "pubmed24n1446.xml\n",
      "pubmed24n1447.xml\n",
      "pubmed24n1448.xml\n",
      "pubmed24n1449.xml\n",
      "pubmed24n1450.xml\n",
      "pubmed24n1451.xml\n",
      "pubmed24n1452.xml\n",
      "pubmed24n1453.xml\n",
      "pubmed24n1454.xml\n",
      "pubmed24n1455.xml\n",
      "pubmed24n1456.xml\n",
      "CPU times: user 1h 46min 38s, sys: 4min 5s, total: 1h 50min 43s\n",
      "Wall time: 1h 50min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = \"/gpfs01/berens/data/data/pubmed/2024_daily_updates/\"\n",
    "\n",
    "files_2024_df_daily_updates = import_all_files(path, order_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4129322 papers\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} papers\".format(files_2024_df_daily_updates.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>AbstractText</th>\n",
       "      <th>Language</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Date</th>\n",
       "      <th>NameFirstAuthor</th>\n",
       "      <th>NameLastAuthor</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>AffiliationFirstAuthor</th>\n",
       "      <th>AffiliationLastAuthor</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1025</td>\n",
       "      <td>Isolation and purification of cytokinin bindin...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Nov 17</td>\n",
       "      <td>T</td>\n",
       "      <td>K</td>\n",
       "      <td>0006-291X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed24n1220.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "      <td>Purification and properties of isoenzymes of c...</td>\n",
       "      <td>Two isoenzymes of an NADP+ -dependent cinnamyl...</td>\n",
       "      <td>eng</td>\n",
       "      <td>European journal of biochemistry</td>\n",
       "      <td>1975 Nov 01</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>0014-2956</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed24n1220.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433</td>\n",
       "      <td>Uptake, translocation, and metabolism of tirpa...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Journal of agricultural and food chemistry</td>\n",
       "      <td>1975 Nov-Dec</td>\n",
       "      <td>J E</td>\n",
       "      <td>R I</td>\n",
       "      <td>0021-8561</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed24n1220.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1314</td>\n",
       "      <td>The soybean answer to food costs.</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Dimensions in health service</td>\n",
       "      <td>1976 Jan</td>\n",
       "      <td>T C</td>\n",
       "      <td>T C</td>\n",
       "      <td>0317-7645</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed24n1220.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Metal substitutions incarbonic anhydrase: a ha...</td>\n",
       "      <td></td>\n",
       "      <td>eng</td>\n",
       "      <td>Biochemical and biophysical research communica...</td>\n",
       "      <td>1975 Oct 27</td>\n",
       "      <td>R J</td>\n",
       "      <td>R G</td>\n",
       "      <td>0006-291X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pubmed24n1220.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PMID                                              Title  \\\n",
       "0  1025  Isolation and purification of cytokinin bindin...   \n",
       "1  1250  Purification and properties of isoenzymes of c...   \n",
       "2   433  Uptake, translocation, and metabolism of tirpa...   \n",
       "3  1314                  The soybean answer to food costs.   \n",
       "4     3  Metal substitutions incarbonic anhydrase: a ha...   \n",
       "\n",
       "                                        AbstractText Language  \\\n",
       "0                                                         eng   \n",
       "1  Two isoenzymes of an NADP+ -dependent cinnamyl...      eng   \n",
       "2                                                         eng   \n",
       "3                                                         eng   \n",
       "4                                                         eng   \n",
       "\n",
       "                                             Journal          Date  \\\n",
       "0  Biochemical and biophysical research communica...   1975 Nov 17   \n",
       "1                   European journal of biochemistry   1975 Nov 01   \n",
       "2         Journal of agricultural and food chemistry  1975 Nov-Dec   \n",
       "3                       Dimensions in health service      1976 Jan   \n",
       "4  Biochemical and biophysical research communica...   1975 Oct 27   \n",
       "\n",
       "  NameFirstAuthor NameLastAuthor       ISSN AffiliationFirstAuthor  \\\n",
       "0               T              K  0006-291X                          \n",
       "1               D              H  0014-2956                          \n",
       "2             J E            R I  0021-8561                          \n",
       "3             T C            T C  0317-7645                          \n",
       "4             R J            R G  0006-291X                          \n",
       "\n",
       "  AffiliationLastAuthor           filename  \n",
       "0                        pubmed24n1220.xml  \n",
       "1                        pubmed24n1220.xml  \n",
       "2                        pubmed24n1220.xml  \n",
       "3                        pubmed24n1220.xml  \n",
       "4                        pubmed24n1220.xml  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_2024_df_daily_updates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter\n",
    "\n",
    "Filter out:\n",
    "- non-English papers\n",
    "- papers with empty abstracts\n",
    "- papers with abstracts shorter than 250 or longer than 4000 symbols\n",
    "- papers with unfinished abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty abstracts and non-english papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before, there were 4129322 papers\n",
      "After eliminating empty abstracts, there are 3712633 papers\n",
      "After first cleaning, there are 3672467 papers\n",
      "CPU times: user 4.77 s, sys: 284 ms, total: 5.06 s\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\n",
    "    \"Before, there were {} papers\".format(\n",
    "        files_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Eliminate empty abstracts\n",
    "clean_2024_df_daily_updates = files_2024_df_daily_updates[\n",
    "    files_2024_df_daily_updates.AbstractText != \"\"\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"After eliminating empty abstracts, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Eliminate non-english papers\n",
    "clean_2024_df_daily_updates = clean_2024_df_daily_updates[\n",
    "    clean_2024_df_daily_updates.Language == \"eng\"\n",
    "]\n",
    "\n",
    "# print size\n",
    "print(\n",
    "    \"After first cleaning, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cut off, there are 3672467 papers\n",
      "After cut off, there are 3665725 papers\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Before cut off, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")\n",
    "abstracts = clean_2024_df_daily_updates[\"AbstractText\"].tolist()\n",
    "len_strings = map(len, abstracts)\n",
    "len_abstracts = np.fromiter(len_strings, dtype=np.int64, count=len(abstracts))\n",
    "\n",
    "\n",
    "cut_off = 4000\n",
    "clean_2024_df_daily_updates = clean_2024_df_daily_updates[\n",
    "    len_abstracts < cut_off\n",
    "]\n",
    "print(\n",
    "    \"After cut off, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After threshold, there are 3640234 papers\n"
     ]
    }
   ],
   "source": [
    "threshold = 250\n",
    "len_short_abstracts = len_abstracts[len_abstracts < cut_off]\n",
    "clean_2024_df_daily_updates = clean_2024_df_daily_updates[\n",
    "    len_short_abstracts > threshold\n",
    "]\n",
    "print(\n",
    "    \"After threshold, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove the truncated sentence from abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = clean_2024_df_daily_updates[\"AbstractText\"]\n",
    "abstracts_list = clean_2024_df_daily_updates[\"AbstractText\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.77 s, sys: 122 ms, total: 4.89 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BUENO\n",
    "clean_2024_df_daily_updates.AbstractText = list(\n",
    "    map(\n",
    "        lambda x, y: x[: y - 1] if y != -1 else x,\n",
    "        clean_2024_df_daily_updates.AbstractText,\n",
    "        clean_2024_df_daily_updates.AbstractText.str.find(\n",
    "            \"ABSTRACT TRUNCATED AT\"\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unfinished abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640234\n"
     ]
    }
   ],
   "source": [
    "abstracts = clean_2024_df_daily_updates[\"AbstractText\"]\n",
    "abstracts_list = clean_2024_df_daily_updates[\"AbstractText\"].tolist()\n",
    "print(len(abstracts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 26.9 ms, total: 1.17 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "end_abstracts = [x[-2:] for x in abstracts_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 2.95 ms, total: 1.82 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "point_index = np.array([x.find(\".\") for x in end_abstracts])\n",
    "question_index = np.array([x.find(\"?\") for x in end_abstracts])\n",
    "exclamation_index = np.array([x.find(\"!\") for x in end_abstracts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning, there are 3640234 papers\n",
      "After cleaning, there are 3638921 papers\n",
      "CPU times: user 1.69 s, sys: 41.9 ms, total: 1.73 s\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\n",
    "    \"Before cleaning, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Eliminate unfinished abstracts\n",
    "clean_2024_df_daily_updates = clean_2024_df_daily_updates[\n",
    "    (point_index != -1) | (question_index != -1) | (exclamation_index != -1)\n",
    "]\n",
    "\n",
    "# print size\n",
    "print(\n",
    "    \"After cleaning, there are {} papers\".format(\n",
    "        clean_2024_df_daily_updates.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save intermediate dataframe\n",
    "\n",
    "# clean_2024_df_daily_updates.to_pickle(\n",
    "#     data_path / \"clean_2024_df_daily_updates_v2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label\n",
    "Generate labels based on the journal title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color_legend = {\n",
    "    \"cancer\": \"black\",\n",
    "    \"neuroscience\": \"#aeaa00\",\n",
    "    \"cardiology\": \"#1CE6FF\",\n",
    "    \"ecology\": \"#FF34FF\",\n",
    "    \"bioinformatics\": \"#FF4A46\",\n",
    "    \"chemistry\": \"#008941\",\n",
    "    \"surgery\": \"#006FA6\",\n",
    "    \"environment\": \"#0089A3\",\n",
    "    \"material\": \"#0000A6\",\n",
    "    \"microbiology\": \"#B79762\",\n",
    "    \"pediatric\": \"#004D43\",\n",
    "    \"immunology\": \"#8FB0FF\",\n",
    "    \"psychology\": \"#5A0007\",\n",
    "    \"psychiatry\": \"#BA0900\",\n",
    "    \"genetics\": \"#1B4400\",\n",
    "    \"nutrition\": \"#4FC601\",\n",
    "    \"veterinary\": \"#3B5DFF\",\n",
    "    \"engineering\": \"#00C2A0\",\n",
    "    \"education\": \"#549E79\",\n",
    "    \"physics\": \"#BC23FF\",\n",
    "    \"optics\": \"#C895C5\",\n",
    "    \"nursing\": \"#FF2F80\",\n",
    "    \"neurology\": \"#009271\",\n",
    "    \"radiology\": \"#00FECF\",\n",
    "    \"ophthalmology\": \"#A4E804\",\n",
    "    \"gynecology\": \"#FFB500\",\n",
    "    \"rehabilitation\": \"#6B002C\",\n",
    "    \"pathology\": \"#FF9408\",\n",
    "    \"anesthesiology\": \"#CC0744\",\n",
    "    \"dermatology\": \"#D790FF\",\n",
    "    \"pharmacology\": \"#5B4534\",\n",
    "    \"physiology\": \"#E83000\",\n",
    "    \"virology\": \"#6F0062\",\n",
    "    \"biochemistry\": \"#b65141\",\n",
    "    \"computation\": \"#C20078\",\n",
    "    \"infectious\": \"#7A4900\",\n",
    "    \"healthcare\": \"#FF90C9\",\n",
    "    \"ethics\": \"#6508ba\",\n",
    "    \"dentistry\": \"#8e4d8a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 32s, sys: 3.16 s, total: 3min 36s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_2024_du, _ = improved_coloring(\n",
    "    clean_2024_df_daily_updates.Journal, label_color_legend\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country\n",
    "Extract first author's affiliation country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = [\n",
    "    \"Afghanistan\",\n",
    "    \"Albania\",\n",
    "    \"Algeria\",\n",
    "    \"Andorra\",\n",
    "    \"Angola\",\n",
    "    \"Antigua and Barbuda\",\n",
    "    \"Argentina\",\n",
    "    \"Armenia\",\n",
    "    \"Australia\",\n",
    "    \"Austria\",\n",
    "    \"Azerbaijan\",\n",
    "    \"Bahamas\",\n",
    "    \"Bahrain\",\n",
    "    \"Bangladesh\",\n",
    "    \"Barbados\",\n",
    "    \"Belarus\",\n",
    "    \"Belgium\",\n",
    "    \"Belize\",\n",
    "    \"Benin\",\n",
    "    \"Bhutan\",\n",
    "    \"Bolivia\",\n",
    "    \"Bosnia and Herzegovina\",\n",
    "    \"Botswana\",\n",
    "    \"Brazil\",\n",
    "    \"Brunei\",\n",
    "    \"Bulgaria\",\n",
    "    \"Burkina Faso\",\n",
    "    \"Burundi\",\n",
    "    \"Cabo Verde\",\n",
    "    \"Cambodia\",\n",
    "    \"Cameroon\",\n",
    "    \"Canada\",\n",
    "    \"Central African Republic\",\n",
    "    \"Chad\",\n",
    "    \"Chile\",\n",
    "    \"China\",\n",
    "    \"Colombia\",\n",
    "    \"Comoros\",\n",
    "    \"Democratic Republic of the Congo\",\n",
    "    \"Republic of the Congo\",\n",
    "    \"Costa Rica\",\n",
    "    \"Côte d’Ivoire\",\n",
    "    \"Croatia\",\n",
    "    \"Cuba\",\n",
    "    \"Cyprus\",\n",
    "    \"Czech Republic\",\n",
    "    \"Denmark\",\n",
    "    \"Djibouti\",\n",
    "    \"Dominica\",\n",
    "    \"Dominican Republic\",\n",
    "    \"East Timor\",\n",
    "    \"Ecuador\",\n",
    "    \"Egypt\",\n",
    "    \"El Salvador\",\n",
    "    \"Equatorial Guinea\",\n",
    "    \"Eritrea\",\n",
    "    \"Estonia\",\n",
    "    \"Eswatini\",\n",
    "    \"Ethiopia\",\n",
    "    \"Fiji\",\n",
    "    \"Finland\",\n",
    "    \"France\",\n",
    "    \"Gabon\",\n",
    "    \"Gambia\",\n",
    "    \"Georgia\",\n",
    "    \"Germany\",\n",
    "    \"Ghana\",\n",
    "    \"Greece\",\n",
    "    \"Grenada\",\n",
    "    \"Guatemala\",\n",
    "    \"Guinea\",\n",
    "    \"Guinea-Bissau\",\n",
    "    \"Guyana\",\n",
    "    \"Haiti\",\n",
    "    \"Honduras\",\n",
    "    \"Hungary\",\n",
    "    \"Iceland\",\n",
    "    \"India\",\n",
    "    \"Indonesia\",\n",
    "    \"Iran\",\n",
    "    \"Iraq\",\n",
    "    \"Ireland\",\n",
    "    \"Israel\",\n",
    "    \"Italy\",\n",
    "    \"Jamaica\",\n",
    "    \"Japan\",\n",
    "    \"Jordan\",\n",
    "    \"Kazakhstan\",\n",
    "    \"Kenya\",\n",
    "    \"Kiribati\",\n",
    "    \"North Korea\",\n",
    "    \"South Korea\",\n",
    "    \"Kosovo\",\n",
    "    \"Kuwait\",\n",
    "    \"Kyrgyzstan\",\n",
    "    \"Laos\",\n",
    "    \"Latvia\",\n",
    "    \"Lebanon\",\n",
    "    \"Nicaragua\",\n",
    "    \"Niger\",\n",
    "    \"Nigeria\",\n",
    "    \"North Macedonia\",\n",
    "    \"Norway\",\n",
    "    \"Oman\",\n",
    "    \"Pakistan\",\n",
    "    \"Palau\",\n",
    "    \"Panama\",\n",
    "    \"Papua New Guinea\",\n",
    "    \"Paraguay\",\n",
    "    \"Peru\",\n",
    "    \"Philippines\",\n",
    "    \"Poland\",\n",
    "    \"Portugal\",\n",
    "    \"Qatar\",\n",
    "    \"Romania\",\n",
    "    \"Russia\",\n",
    "    \"Rwanda\",\n",
    "    \"Saint Kitts and Nevis\",\n",
    "    \"Saint Lucia\",\n",
    "    \"Saint Vincent and the Grenadines\",\n",
    "    \"Samoa\",\n",
    "    \"San Marino\",\n",
    "    \"Sao Tome and Principe\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"Senegal\",\n",
    "    \"Serbia\",\n",
    "    \"Seychelles\",\n",
    "    \"Sierra Leone\",\n",
    "    \"Singapore\",\n",
    "    \"Slovakia\",\n",
    "    \"Slovenia\",\n",
    "    \"Solomon Islands\",\n",
    "    \"Somalia\",\n",
    "    \"South Africa\",\n",
    "    \"Spain\",\n",
    "    \"Sri Lanka\",\n",
    "    \"Sudan\",\n",
    "    \"South Sudan\",\n",
    "    \"Suriname\",\n",
    "    \"Sweden\",\n",
    "    \"Switzerland\",\n",
    "    \"Syria\",\n",
    "    \"Taiwan\",\n",
    "    \"Tajikistan\",\n",
    "    \"Tanzania\",\n",
    "    \"Thailand\",\n",
    "    \"Togo\",\n",
    "    \"Tonga\",\n",
    "    \"Trinidad and Tobago\",\n",
    "    \"Tunisia\",\n",
    "    \"Turkey\",\n",
    "    \"Turkmenistan\",\n",
    "    \"Tuvalu\",\n",
    "    \"Uganda\",\n",
    "    \"Ukraine\",\n",
    "    \"United Arab Emirates\",\n",
    "    \"United Kingdom\",\n",
    "    \"United States\",\n",
    "    \"Uruguay\",\n",
    "    \"Uzbekistan\",\n",
    "    \"Vanuatu\",\n",
    "    \"Vatican City\",\n",
    "    \"Venezuela\",\n",
    "    \"Vietnam\",\n",
    "    \"Yemen\",\n",
    "    \"Zambia\",\n",
    "    \"Zimbabwe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_countries = dict(zip(all_countries, np.arange(1, len(all_countries) + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 53s, sys: 7.34 s, total: 16min\n",
      "Wall time: 16min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "countries_first_author_2024_du, _ = mapping_countries(\n",
    "    clean_2024_df_daily_updates.AffiliationFirstAuthor, dict_countries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [\n",
    "    \"Alabama\",\n",
    "    \"Alaska\",\n",
    "    \"Arizona\",\n",
    "    \"Arkansas\",\n",
    "    \"California\",\n",
    "    \"Colorado\",\n",
    "    \"Connecticut\",\n",
    "    \"Delaware\",\n",
    "    \"Florida\",\n",
    "    \"Georgia\",\n",
    "    \"Hawaii\",\n",
    "    \"Idaho\",\n",
    "    \"Illinois\",\n",
    "    \"Indiana\",\n",
    "    \"Iowa\",\n",
    "    \"Kansas\",\n",
    "    \"Kentucky\",\n",
    "    \"Louisiana\",\n",
    "    \"Maine\",\n",
    "    \"Maryland\",\n",
    "    \"Massachusetts\",\n",
    "    \"Michigan\",\n",
    "    \"Minnesota\",\n",
    "    \"Mississippi\",\n",
    "    \"Missouri\",\n",
    "    \"Montana\",\n",
    "    \"Nebraska\",\n",
    "    \"Nevada\",\n",
    "    \"New Hampshire\",\n",
    "    \"New Jersey\",\n",
    "    \"New Mexico\",\n",
    "    \"New York\",\n",
    "    \"North Carolina\",\n",
    "    \"North Dakota\",\n",
    "    \"Ohio\",\n",
    "    \"Oklahoma\",\n",
    "    \"Oregon\",\n",
    "    \"Pennsylvania\",\n",
    "    \"Rhode Island\",\n",
    "    \"South Carolina\",\n",
    "    \"South Dakota\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"Utah\",\n",
    "    \"Vermont\",\n",
    "    \"Virginia\",\n",
    "    \"Washington\",\n",
    "    \"West Virginia\",\n",
    "    \"Wisconsin\",\n",
    "    \"Wyoming\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_states = dict(zip(all_states, np.arange(1, len(all_states) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 36s, sys: 1.78 s, total: 4min 37s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_usa_states_first_author_2024_du, _ = mapping_states(\n",
    "    clean_2024_df_daily_updates.AffiliationFirstAuthor, dict_all_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct USA country with states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_first_author_2024_usa_corrected = np.where(\n",
    "    labels_usa_states_first_author_2024_du != \"unknown\",\n",
    "    \"United States\",\n",
    "    countries_first_author_2024_du,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of US papers before correcting 22.45553008707801\n",
      "Percentage of US papers after correcting 27.090585368574914\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of US papers before correcting\",\n",
    "    np.sum(countries_first_author_2024_du == \"United States\")\n",
    "    / countries_first_author_2024_du.shape[0]\n",
    "    * 100,\n",
    ")\n",
    "print(\n",
    "    \"Percentage of US papers after correcting\",\n",
    "    np.sum(countries_first_author_2024_usa_corrected == \"United States\")\n",
    "    / countries_first_author_2024_du.shape[0]\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook we use the `gender` R package. You can install them in R via comannd `install.packages(\"gender\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate first name lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_first_author = clean_2024_df_daily_updates.NameFirstAuthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentge of no names:  0.19906999904642061\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentge of no names: \",\n",
    "    np.sum(name_first_author == \"\") / len(name_first_author) * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 17.8 ms, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_first_author = [\n",
    "    elem.split()[0] if elem != \"\" else elem for elem in name_first_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 805 ms, sys: 4.59 ms, total: 809 ms\n",
      "Wall time: 810 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_first_author = [\n",
    "    elem.split(\"-\")[0] if elem != \"\" else elem\n",
    "    for elem in sliced_name_first_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 304 ms, sys: 952 µs, total: 305 ms\n",
      "Wall time: 304 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sliced_name_first_author = [len(x) for x in sliced_name_first_author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of names that are just initials:  4.865398287019696\n"
     ]
    }
   ],
   "source": [
    "n_initials = len(\n",
    "    np.array(len_sliced_name_first_author)[\n",
    "        np.array(len_sliced_name_first_author) == 1\n",
    "    ]\n",
    ")\n",
    "n_total_papers = len(np.array(len_sliced_name_first_author))\n",
    "print(\n",
    "    \"Percentage of names that are just initials: \",\n",
    "    n_initials / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of papers with missing names:  0.19934480578171387\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of papers with missing names: \",\n",
    "    np.sum(np.array(sliced_name_first_author) == \"\")\n",
    "    / len(sliced_name_first_author)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing names:  7254\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of missing names: \",\n",
    "    len(\n",
    "        np.array(sliced_name_first_author)[\n",
    "            np.array(sliced_name_first_author) == \"\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 765 ms, sys: 355 µs, total: 766 ms\n",
      "Wall time: 764 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_name_first_author = np.where(\n",
    "    np.array(len_sliced_name_first_author) == 1, \"\", sliced_name_first_author\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of initials + missing names:  5.06474309280141\n"
     ]
    }
   ],
   "source": [
    "n_initials_and_missing = len(\n",
    "    np.array(filtered_name_first_author)[\n",
    "        np.array(filtered_name_first_author) == \"\"\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Percentage of initials + missing names: \",\n",
    "    n_initials_and_missing / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_last_author = clean_2024_df_daily_updates.NameLastAuthor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 887 ms, sys: 17.8 ms, total: 905 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_last_author = [\n",
    "    elem.split()[0] if elem != \"\" else elem for elem in name_last_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 683 ms, sys: 7.79 ms, total: 691 ms\n",
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sliced_name_last_author = [\n",
    "    elem.split(\"-\")[0] if elem != \"\" else elem\n",
    "    for elem in sliced_name_last_author\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 269 ms, sys: 4.79 ms, total: 273 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sliced_name_last_author = [len(x) for x in sliced_name_last_author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of names that are just initials:  5.3387254078887665\n"
     ]
    }
   ],
   "source": [
    "n_initials = len(\n",
    "    np.array(len_sliced_name_last_author)[\n",
    "        np.array(len_sliced_name_last_author) == 1\n",
    "    ]\n",
    ")\n",
    "n_total_papers = len(np.array(len_sliced_name_last_author))\n",
    "print(\n",
    "    \"Percentage of names that are just initials: \",\n",
    "    n_initials / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing names:  56531\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of missing names: \",\n",
    "    len(\n",
    "        np.array(sliced_name_last_author)[\n",
    "            np.array(sliced_name_last_author) == \"\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 919 ms, sys: 2.19 ms, total: 921 ms\n",
      "Wall time: 921 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_name_last_author = np.where(\n",
    "    np.array(len_sliced_name_last_author) == 1, \"\", sliced_name_last_author\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of initials + missing names:  6.892235363174963\n"
     ]
    }
   ],
   "source": [
    "n_initials_and_missing = len(\n",
    "    np.array(filtered_name_last_author)[\n",
    "        np.array(filtered_name_last_author) == \"\"\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Percentage of initials + missing names: \",\n",
    "    n_initials_and_missing / n_total_papers * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Loading required package: gender\n",
      "\n",
      "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Loading required package: tibble\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>BoolVector with 1 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "                   1\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.BoolVector object at 0x7f11c0431f80> [RTYPES.LGLSXP]\n",
       "R classes: ('logical',)\n",
       "[       1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(gender)\n",
    "%R require(tibble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_year = clean_2024_df_daily_updates.Date.str.extract(\"([12]\\d\\d\\d)\").values.astype(int)\n",
    "date_year = np.array([elem[0] for elem in date_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638916</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mahtab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638917</th>\n",
       "      <td>2024</td>\n",
       "      <td>Takeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638918</th>\n",
       "      <td>2024</td>\n",
       "      <td>Siobhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638919</th>\n",
       "      <td>2024</td>\n",
       "      <td>Fahimeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638920</th>\n",
       "      <td>2024</td>\n",
       "      <td>Federica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3638921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Years     Names\n",
       "0         1975          \n",
       "1         1975          \n",
       "2         1975          \n",
       "3         1977          \n",
       "4         1977          \n",
       "...        ...       ...\n",
       "3638916   2024    Mahtab\n",
       "3638917   2024     Takeo\n",
       "3638918   2024   Siobhan\n",
       "3638919   2024   Fahimeh\n",
       "3638920   2024  Federica\n",
       "\n",
       "[3638921 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I initialize a dataframe where I will store year, name and gender\n",
    "# This will be the dataframe `year_name_gender_first_author_df'\n",
    "\n",
    "df_subset = pd.DataFrame(\n",
    "    {\"Years\": date_year, \"Names\": filtered_name_first_author}\n",
    ")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  1928\n",
      "Year:  1929\n",
      "Year:  1930\n",
      "Year:  1931\n",
      "Year:  1932\n",
      "Year:  1933\n",
      "Year:  1934\n",
      "Year:  1935\n",
      "Year:  1936\n",
      "Year:  1937\n",
      "Year:  1939\n",
      "Year:  1941\n",
      "Year:  1945\n",
      "Year:  1946\n",
      "Year:  1948\n",
      "Year:  1953\n",
      "Year:  1955\n",
      "Year:  1956\n",
      "Year:  1957\n",
      "Year:  1958\n",
      "Year:  1959\n",
      "Year:  1960\n",
      "Year:  1961\n",
      "Year:  1962\n",
      "Year:  1963\n",
      "Year:  1964\n",
      "Year:  1965\n",
      "Year:  1966\n",
      "Year:  1967\n",
      "Year:  1968\n",
      "Year:  1969\n",
      "Year:  1970\n",
      "Year:  1971\n",
      "Year:  1972\n",
      "Year:  1973\n",
      "Year:  1974\n",
      "Year:  1975\n",
      "Year:  1976\n",
      "Year:  1977\n",
      "Year:  1978\n",
      "Year:  1979\n",
      "Year:  1980\n",
      "Year:  1981\n",
      "Year:  1982\n",
      "Year:  1983\n",
      "Year:  1984\n",
      "Year:  1985\n",
      "Year:  1986\n",
      "Year:  1987\n",
      "Year:  1988\n",
      "Year:  1989\n",
      "Year:  1990\n",
      "Year:  1991\n",
      "Year:  1992\n",
      "Year:  1993\n",
      "Year:  1994\n",
      "Year:  1995\n",
      "Year:  1996\n",
      "Year:  1997\n",
      "Year:  1998\n",
      "Year:  1999\n",
      "Year:  2000\n",
      "Year:  2001\n",
      "Year:  2002\n",
      "Year:  2003\n",
      "Year:  2004\n",
      "Year:  2005\n",
      "Year:  2006\n",
      "Year:  2007\n",
      "Year:  2008\n",
      "Year:  2009\n",
      "Year:  2010\n",
      "Year:  2011\n",
      "Year:  2012\n",
      "Year:  2013\n",
      "Year:  2014\n",
      "Year:  2015\n",
      "Year:  2016\n",
      "Year:  2017\n",
      "Year:  2018\n",
      "Year:  2019\n",
      "Year:  2020\n",
      "Year:  2021\n",
      "Year:  2022\n",
      "Year:  2023\n",
      "Year:  2024\n",
      "Year:  2025\n",
      "Year:  2026\n",
      "CPU times: user 1min 21s, sys: 420 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>proportion_male</th>\n",
       "      <th>proportion_female</th>\n",
       "      <th>gender</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carl</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>male</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>female</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horace</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harriet</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Horace</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>male</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025803</th>\n",
       "      <td>Yi</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025804</th>\n",
       "      <td>Yi</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025805</th>\n",
       "      <td>Yuchen</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025806</th>\n",
       "      <td>Kristin</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025807</th>\n",
       "      <td>Kristin</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2025808 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  proportion_male  proportion_female  gender  year_min  \\\n",
       "0             Carl           0.9948             0.0052    male    1959.0   \n",
       "1        Charlotte           0.0026             0.9974  female    1959.0   \n",
       "2           Horace           1.0000             0.0000    male    1959.0   \n",
       "3          Harriet           0.0000             1.0000  female    1960.0   \n",
       "4           Horace           0.9875             0.0125    male    1960.0   \n",
       "...            ...              ...                ...     ...       ...   \n",
       "2025803         Yi           1.0000             0.0000    male    2012.0   \n",
       "2025804         Yi           1.0000             0.0000    male    2012.0   \n",
       "2025805     Yuchen           1.0000             0.0000    male    2012.0   \n",
       "2025806    Kristin           0.0000             1.0000  female    2012.0   \n",
       "2025807    Kristin           0.0000             1.0000  female    2012.0   \n",
       "\n",
       "         year_max  \n",
       "0          1959.0  \n",
       "1          1959.0  \n",
       "2          1959.0  \n",
       "3          1960.0  \n",
       "4          1960.0  \n",
       "...           ...  \n",
       "2025803    2012.0  \n",
       "2025804    2012.0  \n",
       "2025805    2012.0  \n",
       "2025806    2012.0  \n",
       "2025807    2012.0  \n",
       "\n",
       "[2025808 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# I predict the gender of those names sorting the df by year.\n",
    "# The problem is that the returned df does not have the same dimensions as the original, since not all the papers have names.\n",
    "# Therefore, the next two steps are necessary\n",
    "\n",
    "gender_prediction_df = pd.DataFrame()\n",
    "unique_years = np.unique(df_subset.Years)\n",
    "\n",
    "for year in unique_years:\n",
    "    print(\"Year: \", year)\n",
    "\n",
    "    df_grouped_year = df_subset.groupby(\"Years\").get_group(year)\n",
    "    df_names = df_grouped_year.Names\n",
    "\n",
    "    # cases for years outside interval\n",
    "    if year <= 1930:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 1930, method = \"ssa\")\n",
    "\n",
    "    if year >= 2012:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 2012, method = \"ssa\")\n",
    "\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        %R library(gender)\n",
    "        %R -i df_names -i year -o result result = gender(df_names, years = year, method = \"ssa\")\n",
    "\n",
    "    gender_prediction_df = pd.concat(\n",
    "        [gender_prediction_df, result], ignore_index=True\n",
    "    )\n",
    "\n",
    "gender_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 19.9 ms, total: 12.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1939, 1941, 1945, 1946, 1948, 1953, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# In here I am creating a dictionary that has a map name-gender for every year, based on the predictions from the dataframe above (because they are year dependent).\n",
    "# I do some tricks to create mappings for also years that were not predicted, and years outside the available `ssa' intervals (<1930, >2012)\n",
    "\n",
    "unique_predicted_years = np.unique(gender_prediction_df[\"year_min\"])\n",
    "gender_maps_years = {}\n",
    "for year in unique_years:\n",
    "    if year >= 2012:\n",
    "        eff_year = 2012\n",
    "    if year <= 1930:\n",
    "        eff_year = 1930\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        eff_year = year\n",
    "\n",
    "    if eff_year not in unique_predicted_years:\n",
    "        closest_year = unique_predicted_years[\n",
    "            (unique_predicted_years - eff_year).argmin()\n",
    "        ]\n",
    "\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(closest_year)\n",
    "\n",
    "    else:\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(eff_year)\n",
    "\n",
    "    gender_map = dict(\n",
    "        zip(\n",
    "            gender_prediction_grouped_year.name,\n",
    "            gender_prediction_grouped_year.gender,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gender_maps_years[year] = gender_map\n",
    "\n",
    "gender_maps_years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1939\n",
      "1941\n",
      "1945\n",
      "1946\n",
      "1948\n",
      "1953\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "CPU times: user 1min 33s, sys: 603 ms, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638916</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mahtab</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638917</th>\n",
       "      <td>2024</td>\n",
       "      <td>Takeo</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638918</th>\n",
       "      <td>2024</td>\n",
       "      <td>Siobhan</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638919</th>\n",
       "      <td>2024</td>\n",
       "      <td>Fahimeh</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638920</th>\n",
       "      <td>2024</td>\n",
       "      <td>Federica</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3638921 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Years     Names   Gender\n",
       "0         1975            unknown\n",
       "1         1975            unknown\n",
       "2         1975            unknown\n",
       "3         1977            unknown\n",
       "4         1977            unknown\n",
       "...        ...       ...      ...\n",
       "3638916   2024    Mahtab  unknown\n",
       "3638917   2024     Takeo     male\n",
       "3638918   2024   Siobhan   female\n",
       "3638919   2024   Fahimeh  unknown\n",
       "3638920   2024  Federica   female\n",
       "\n",
       "[3638921 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Now, using the name-gender maps created above, I map the names in the original dataframe (df_subset) to their respective genders, saving them in a new column 'Gender'\n",
    "\n",
    "# here I add a 'Gender' column to the df_subset\n",
    "df_subset[\"Gender\"] = [\"unknown\"] * df_subset.shape[0]\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "\n",
    "    df_subset_year = (\n",
    "        df_subset.groupby(\"Years\")\n",
    "        .get_group(year)\n",
    "        .Names.apply(lambda x: np.vectorize(gender_maps_years[year].get)(x))\n",
    "    )\n",
    "    df_subset_year.rename(\"Gender\", inplace=True)\n",
    "    df_subset.update(df_subset_year)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025808"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the number of predicted genders matches the length of the df with the predictions above\n",
    "len(df_subset[df_subset.Gender != \"unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save\n",
    "gender_first_author = df_subset.Gender.to_numpy(dtype=str)\n",
    "np.save(variables_path / \"gender_first_author\", gender_first_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638916</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mohammad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638917</th>\n",
       "      <td>2024</td>\n",
       "      <td>Atsushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638918</th>\n",
       "      <td>2024</td>\n",
       "      <td>Clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638919</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mehdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638920</th>\n",
       "      <td>2024</td>\n",
       "      <td>Franco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3638921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Years     Names\n",
       "0         1975          \n",
       "1         1975          \n",
       "2         1975          \n",
       "3         1977          \n",
       "4         1977          \n",
       "...        ...       ...\n",
       "3638916   2024  Mohammad\n",
       "3638917   2024   Atsushi\n",
       "3638918   2024     Clara\n",
       "3638919   2024     Mehdi\n",
       "3638920   2024    Franco\n",
       "\n",
       "[3638921 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = pd.DataFrame(\n",
    "    {\"Years\": date_year, \"Names\": filtered_name_last_author}\n",
    ")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1939\n",
      "1941\n",
      "1945\n",
      "1946\n",
      "1948\n",
      "1953\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "CPU times: user 1min 16s, sys: 787 ms, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>proportion_male</th>\n",
       "      <th>proportion_female</th>\n",
       "      <th>gender</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frank</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>male</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Herbert</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>male</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>male</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>male</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>male</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040112</th>\n",
       "      <td>Yan</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040113</th>\n",
       "      <td>Zai</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040114</th>\n",
       "      <td>Zai</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040115</th>\n",
       "      <td>Kiran</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040116</th>\n",
       "      <td>Kiran</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>male</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2040117 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  proportion_male  proportion_female gender  year_min  \\\n",
       "0            Frank           0.9954             0.0046   male    1959.0   \n",
       "1          Herbert           0.9966             0.0034   male    1959.0   \n",
       "2           Joseph           0.9967             0.0033   male    1959.0   \n",
       "3        Alexander           0.9888             0.0112   male    1960.0   \n",
       "4          Charles           0.9953             0.0047   male    1960.0   \n",
       "...            ...              ...                ...    ...       ...   \n",
       "2040112        Yan           1.0000             0.0000   male    2012.0   \n",
       "2040113        Zai           0.5270             0.4730   male    2012.0   \n",
       "2040114        Zai           0.5270             0.4730   male    2012.0   \n",
       "2040115      Kiran           0.7229             0.2771   male    2012.0   \n",
       "2040116      Kiran           0.7229             0.2771   male    2012.0   \n",
       "\n",
       "         year_max  \n",
       "0          1959.0  \n",
       "1          1959.0  \n",
       "2          1959.0  \n",
       "3          1960.0  \n",
       "4          1960.0  \n",
       "...           ...  \n",
       "2040112    2012.0  \n",
       "2040113    2012.0  \n",
       "2040114    2012.0  \n",
       "2040115    2012.0  \n",
       "2040116    2012.0  \n",
       "\n",
       "[2040117 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gender_prediction_df = pd.DataFrame()\n",
    "unique_years = np.unique(df_subset.Years)\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "    df_grouped_year = df_subset.groupby(\"Years\").get_group(year)\n",
    "    df_names = df_grouped_year.Names\n",
    "\n",
    "    # cases for years outside interval\n",
    "    if year <= 1930:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 1930, method = \"ssa\")\n",
    "\n",
    "    if year >= 2012:\n",
    "        %R library(gender)\n",
    "        %R -i df_names -o result result = gender(df_names, years = 2012, method = \"ssa\")\n",
    "\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        %R library(gender)\n",
    "        %R -i df_names -i year -o result result = gender(df_names, years = year, method = \"ssa\")\n",
    "\n",
    "    gender_prediction_df = pd.concat(\n",
    "        [gender_prediction_df, result], ignore_index=True\n",
    "    )\n",
    "\n",
    "gender_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 55.5 ms, total: 12 s\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1939, 1941, 1945, 1946, 1948, 1953, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_predicted_years = np.unique(gender_prediction_df[\"year_min\"])\n",
    "gender_maps_years = {}\n",
    "for year in unique_years:\n",
    "    if year >= 2012:\n",
    "        eff_year = 2012\n",
    "    if year <= 1930:\n",
    "        eff_year = 1930\n",
    "    if (year < 2012) & (year > 1930):\n",
    "        eff_year = year\n",
    "\n",
    "    if eff_year not in unique_predicted_years:\n",
    "        closest_year = unique_predicted_years[\n",
    "            (unique_predicted_years - eff_year).argmin()\n",
    "        ]\n",
    "\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(closest_year)\n",
    "\n",
    "    else:\n",
    "        gender_prediction_grouped_year = gender_prediction_df.groupby(\n",
    "            \"year_min\"\n",
    "        ).get_group(eff_year)\n",
    "\n",
    "    gender_map = dict(\n",
    "        zip(\n",
    "            gender_prediction_grouped_year.name,\n",
    "            gender_prediction_grouped_year.gender,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gender_maps_years[year] = gender_map\n",
    "\n",
    "gender_maps_years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1939\n",
      "1941\n",
      "1945\n",
      "1946\n",
      "1948\n",
      "1953\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "CPU times: user 1min 32s, sys: 333 ms, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Names</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638916</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mohammad</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638917</th>\n",
       "      <td>2024</td>\n",
       "      <td>Atsushi</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638918</th>\n",
       "      <td>2024</td>\n",
       "      <td>Clara</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638919</th>\n",
       "      <td>2024</td>\n",
       "      <td>Mehdi</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638920</th>\n",
       "      <td>2024</td>\n",
       "      <td>Franco</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3638921 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Years     Names   Gender\n",
       "0         1975            unknown\n",
       "1         1975            unknown\n",
       "2         1975            unknown\n",
       "3         1977            unknown\n",
       "4         1977            unknown\n",
       "...        ...       ...      ...\n",
       "3638916   2024  Mohammad     male\n",
       "3638917   2024   Atsushi  unknown\n",
       "3638918   2024     Clara   female\n",
       "3638919   2024     Mehdi     male\n",
       "3638920   2024    Franco     male\n",
       "\n",
       "[3638921 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_subset[\"Gender\"] = [\"unknown\"] * df_subset.shape[0]\n",
    "\n",
    "for year in unique_years:\n",
    "    print(year)\n",
    "\n",
    "    df_subset_year = (\n",
    "        df_subset.groupby(\"Years\")\n",
    "        .get_group(year)\n",
    "        .Names.apply(lambda x: np.vectorize(gender_maps_years[year].get)(x))\n",
    "    )\n",
    "    df_subset_year.rename(\"Gender\", inplace=True)\n",
    "    df_subset.update(df_subset_year)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040117"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the number of predicted genders matches the length of the df with the predictions above\n",
    "len(df_subset[df_subset.Gender != \"unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save\n",
    "gender_last_author = df_subset.Gender.to_numpy(dtype=str)\n",
    "np.save(variables_path / \"gender_last_author_2024\", gender_last_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- PMID\n",
    "- abstract\n",
    "- journal\n",
    "- publication year (update also preprocess-and-count bc the year is being extracted there)\n",
    "- label\n",
    "- affiliation country (from the first affiliation of the first author).\n",
    "- inferred gender of first and last author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variables_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvariables_path\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variables_path' is not defined"
     ]
    }
   ],
   "source": [
    "variables_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_2024_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_2024_df\u001b[49m[\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPMID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstractText\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJournal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m ]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_2024_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = clean_2024_df[\n",
    "    [\"PMID\", \"Title\",\"AbstractText\", \"Journal\", \"Date\"]\n",
    "].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_2024_du' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlabels_2024_du\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_2024_du' is not defined"
     ]
    }
   ],
   "source": [
    "labels_2024_du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"] = df.Date.str.extract(\"([12]\\d\\d\\d)\").values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          1975 Nov 01\n",
       "6             1975 Dec\n",
       "9             1975 Dec\n",
       "11         1977 May 11\n",
       "12            1977 Feb\n",
       "              ...     \n",
       "4129316    2024 Jun 30\n",
       "4129317    2024 Jun 29\n",
       "4129319       2024 Jul\n",
       "4129320    2024 Jun 30\n",
       "4129321    2024 Jun 29\n",
       "Name: Date, Length: 3638921, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Labels\"] = labels_2024_du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Countries\"] = countries_first_author_2024_usa_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InferredGenderFirstAuthor\"] = gender_first_author\n",
    "df[\"InferredGenderLastAuthor\"] = gender_last_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3638921"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"PMID\"], as_index=False).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1987842 new papers\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(df)} new papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>AbstractText</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Year</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Countries</th>\n",
       "      <th>InferredGenderFirstAuthor</th>\n",
       "      <th>InferredGenderLastAuthor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10021341</td>\n",
       "      <td>Left-right asymmetry in vertebrates is control...</td>\n",
       "      <td>Development (Cambridge, England)</td>\n",
       "      <td>1999</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>Germany</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10021363</td>\n",
       "      <td>In plants, post-transcriptional gene silencing...</td>\n",
       "      <td>Current biology : CB</td>\n",
       "      <td>1999</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>France</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10021457</td>\n",
       "      <td>It has been controversial whether high water p...</td>\n",
       "      <td>The Journal of clinical investigation</td>\n",
       "      <td>1999</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>United States</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10021458</td>\n",
       "      <td>Inherited defects in the degradation of glycos...</td>\n",
       "      <td>The Journal of clinical investigation</td>\n",
       "      <td>1999</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>United States</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10021462</td>\n",
       "      <td>Peanut allergy is a significant IgE-mediated h...</td>\n",
       "      <td>The Journal of clinical investigation</td>\n",
       "      <td>1999</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>United States</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                       AbstractText  \\\n",
       "0  10021341  Left-right asymmetry in vertebrates is control...   \n",
       "1  10021363  In plants, post-transcriptional gene silencing...   \n",
       "2  10021457  It has been controversial whether high water p...   \n",
       "3  10021458  Inherited defects in the degradation of glycos...   \n",
       "4  10021462  Peanut allergy is a significant IgE-mediated h...   \n",
       "\n",
       "                                 Journal  Year     Labels      Countries  \\\n",
       "0       Development (Cambridge, England)  1999  unlabeled        Germany   \n",
       "1                   Current biology : CB  1999  unlabeled         France   \n",
       "2  The Journal of clinical investigation  1999  unlabeled  United States   \n",
       "3  The Journal of clinical investigation  1999  unlabeled  United States   \n",
       "4  The Journal of clinical investigation  1999  unlabeled  United States   \n",
       "\n",
       "  InferredGenderFirstAuthor InferredGenderLastAuthor  \n",
       "0                   unknown                  unknown  \n",
       "1                   unknown                  unknown  \n",
       "2                   unknown                  unknown  \n",
       "3                   unknown                  unknown  \n",
       "4                   unknown                  unknown  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 3765600256 bytes == 0x8caf1c000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 5.29 s, total: 3min 35s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "compression_opts = dict(\n",
    "    method=\"zip\", archive_name=\"pubmed_daily_updates_2024_v2.csv\"\n",
    ")\n",
    "\n",
    "df.to_csv(\n",
    "    data_path / \"pubmed_daily_updates_2024_v2.zip\",\n",
    "    index=False,\n",
    "    compression=compression_opts,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
